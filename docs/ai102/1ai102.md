# Azure AI Engineer Associate Certification - AI102

## 1 AI VS GenAI

### 1-1 What is Artificial Intelligence (AI)?

AI is computer systems that perform tasks typically requiring human intelligence.

These include:

* problem-solving
* decision-making
* understanding natural language
* recognizing speech and images


> AI's goal is to **interpret, analyze, and respond to human actions**.
> 
> To simulate human intelligence in machines.

* Simulate: mimic aspects, resembles behaviour
* Emulate: replicates exact processes and mechanisms.

AI applications are vast and include areas like:

* expert systems
* natural language processing
* speech recognition
* robotics

**AI is used in various industries for tasks such as:**

* **B2C** : customer service chatbots
* **commerce**: recommendation systems
* **Auto**: autonomous vehicles
* **Medical**: medical diagnosis.

### What is Generative AI?

Generative AI (GenAI) is a subset of AI that focuses on **creating new content or data** that is novel and realistic. It can interpret or analyze data but also **generates new data itself**.

**It includes generating text, images, music, speech, and other forms of media.**

It often involves advanced machine learning techniques:

* Generative Adversarial Networks (GANs)
* Variational Autoencoders (VAEs)
* Transformer models g GPT

**Generative AI has multiple modalities:**

* **Vision**: realistic images and videos
* **Text**: generating human-like text
* **Audio**: composing music
* **Molecular**: Drug discovery via genomic data

> Large Language Models (LLMs) which generate out human-like text is a subset of GenAl but is often
conflating with being Al due to it being the most popular and developed.


![Alt Image Text](../images/ai102_1_1.png "Body image")

### What is a Foundational Model?

A Foundational Model (FM) is a general purpose model that is trained on vast amounts of data.


We say that an FM is pretrained because it can be fined tuned for specific tasks.


![Alt Image Text](../images/ai102_1_2.png "Body image")


> Ms are a specialized subset of FMs that uses transformer architecture.

## 2 What is a Large Language Model (LLM)?

A Large Language Model (LLM) is a Foundational Model **that implements the transformer architecture.**

![Alt Image Text](../images/ai102_1_3.png "Body image")

During this training phase, the model learns semantics (patterns) of language, such as grammar, word usage, sentence structure, style and tone.


> It is simple to say that LLM just predicts the next sequences of words, but researchers don't know how LLMs generate their outputs.

### Transformer Architecture

**Transformer Architecture** was developed by researchers at Google that is effective at
**Natural Language Processing (NLP)** due to **multi-head attention** and **positional encoding**.

![Alt Image Text](../images/ai102_1_4.png "Body image")

**1. Encoder: reads and understands the input text**. 

It's like a smart system that goes through everything it's been taught (which is a lot of text) and picks up on the meanings of words and how they're used in different contexts.

### **Tokens and Capacity**

**When using transformers the decoder continuously feeds the sequence of tokens back** in as output to help predict the next word in the input.

![Alt Image Text](../images/ai102_1_5.png "Body image")

**Memory**

* Each token in a sequence requires memory

* As the token count increases, the memory increases.
 
* The memory usage eventually becomes exhausted.

**Compute**

model perform more operations for each additional token
Longer sequences require more compute

> AI services that offer Models-as-a-Service will often have a limit of combined input and output.

### What are Embeddings?

**What is a Vector?**

An arrow with a length and a direction

**What is a Vector Space Model?**

Represents text documents or other types of data as vectors in a High Dimensional space


![Alt Image Text](../images/ai102_1_6.png "Body image")

**What are embeddings?**

They are vectors of data used by ML models to **find relationships between data.**

ML models can also create embeddings.

_**Different embedding algorithms capture different kinds of relationships.**_

> You can think of embeddings as external memory for performing a task for ML models.
> 
> 
> Embeddings can be shared across models (Multi-model pattern) to help coordinate a task between models.

### Positional encoding 

**Positional encoding** is a technique used to preserve **order of words** when processing natural language.

Transformers need positional encoders because **they do not process data sequentially** and would lose order of understanding when analyze large bodies of text.

![Alt Image Text](../images/ai102_1_7.png "Body image")

> Positional encoding adds a **positional vector** to each word to keep track of the positions of the words.

### Attention 

**Attention** figures out how each word (or token) **in a sequence** is important to other words within that sequence by assigning the words weights.

#### **Self-Attention**

Computes attention weights within the same input sequence, where each element attends to all other elements.

> Used in transformers to model relationships in
sequences (e.g., words in a sentence).

#### Cross-Attention

Computes attention weights between two different sequences. allowing one sequence to attend to another sequence.

> Used in tasks like translation where the output sequence (decoder) needs to focus on the input sequence (encoder).

#### Multi-head Attention

Combines multiple self-attention (or cross-attention) heads in parallel, each focusing on different aspects of the input.

> Used in transformers to improve performance and capture various dependencies simultaneously.

**Multi-headed** because it receiving multiple inputs

**Self-Attention** Self-attention because it feeds back its own sequence

![Alt Image Text](../images/ai102_1_8.png "Body image")

**Multi-headed** because it receiving multiple inputs

**Cross-attention** because it feeds sequence inputs from two different sources

## Supervised  vs Unsupervised vs Reinforcement

### Supervised Learning (SL)

Data that has been labeled for training Task-driven - **make a prediction**

* When the labels are known and you want a precise outcome.
* When you need a specific value returned

eg. Classification, Regression

### Unsupervised Learning (SL)

Data has not been labeled, the ML model needs to
do its own labeling

**Data-driven - recognize a structure or pattern**

* When the labels are not known and the outcome does not need to be precise.
* When you're trying to make sense of data.

eg. Clustering, Dimensionality Reduction, Association

### Reinforcement Learning (RI)

There is no data, there is an environment and an ML model generates data any many attempt to reach a goal

**Decisions-driven - Game AI, Learning Tasks, Robot
Navigation**

### Neural Networks and Deep Learning

**Activation Functions**

An algorithm applied to a hidden layer node that affects connected output e.g. ReLu

**Dense**

When the next layer increases the amount of nodes

**Sparse**

When the next layer decreases the amount of nodes

**What are Neural Networks? (NN)**

* Often described as **mimicking the brain**, a **neuron/node represents an algorithm**.
* Data is inputted into a neuron and based on the output the data will be passed to
* one of many other connected neurals.
* The connection between neurons is weighted.
* The network is organized in layers.
* There will be a input layer, 1 to many hidden layers and an output layer.


**What is Deep Learning?**

A neural network that has **3 or more hidden layers** is considered deep learning.

**What is Feed Forward? (FNN)**

Neural Networks where connections between nodes do not form a cycle (always move forward)

**What is Backpropagation (BP)?**

Moves backwards through the neural network adjusting weights to improve outcome on next iteration. This is how a neural net learns.

**Loss Function**

A function that compares the ground truth to the prediction to determine the error rate (how bad the network performed)

![Alt Image Text](../images/ai102_1_9.png "Body image")

## What is a GPU?

A General Processing Unit (GPU) that is specially designed to quickly render high-resolution images and video **concurrently**.

GPUs can perform **<mark>parallel operations on multiple sets of data</mark>**, and so they are commonly used for **non-graphical tasks such as machine learning** and scientific computation.

CPU can have **average 4 to 16 processor cores.**

GPU can thousands of processor cores 4 to 8 GPUs can provide as many as 40.000 cores

GPUs are best suited for repetitive and highly-parallel computing tasks:

* Rendering graphics
* Cryptocurrency mining

![Alt Image Text](../images/ai102_1_10.png "Body image")

### What is CUDA?

**What is NVIDA?**

NVIDA is a company that manufactures **graphical processing units (GPUs)** for gaming and professional markets


**What is CUDA?**

Compute Unified Device Architecture (CUDA) is a **parallel computing platform** and **API**
by NVIDIA that allows developers to use **CUDA-enabled GPUs** for **general-purpose
computing on GPUs (GPGPU)**


All major deep learning frameworks are integrated with **NVIDIA Deep Learning SDK**

The NVIDA Deep Learning SDK is a collection of NVIDIA libraries for deep learning.

One of those libraries is the **CUDA Deep Neural Network library (cuDNN)**

cuDNN provides highly tuned implementations for standard routines such as:

* forward and backward convolution
* Pooling
* Normalization
* activation layers

### What is Jupyter Notebook?

**Jupyter Notebook**

A Web-based application for authoring documents that combine:

* live-code
* narrative text
* equations
* visualizations

iPython's notebook feature became Jupyter Notebook

Jupyter Notebooks were overhauled and better **integrated into an IDE called JupyterLab**


You generally want to open Notebooks in Labs

The legacy web-based interface is known as **Jupyter classic notebook**

![Alt Image Text](../images/ai102_1_11.png "Body image")

### What is JupyterLab?

**JupyterLab is a a next-generation web-based user interface**

All the familiar features of the classic Jupyter Notebook in a flexible and powerful user interface:

* notebook
* Terminal
* text editor
* file browser
* rich outputs

JupyterLab will ***eventually replace*** the classic Jupyter Notebook

![Alt Image Text](../images/ai102_1_13.png "Body image")

## Responsible AI

**Responsible AI focuses on ethical, transparent and accountable use of AI** technologies

Microsoft puts into practice Responsible AI via its six Microsoft AI principles


1. **Fairness** - AI systems should treat all people fairly
2. **Reliability and Safety** - AI systems should perform reliably and safely
3. **Privacy and Security** - AI systems should be secure and respect privacy
4. **Inclusiveness** - AI systems should empower everyone and engage people
5. **Transparency** - AI systems should be understandable
6. **Accountability** - People should be accountable for AI systems


### Fairness

* AI systems should treat all people fairly
* AI systems can reinforce existing societal stereotypical
* Bias can be introduced during the development of a pipeline

**AI systems that are used to allocate or withhold:**

* opportunities
* resources
* Information

**In domains:**

* Criminal Justice
* Employment and Hiring
* Finance and Credit

eg. an ML model designed to select final applicants for a hiring pipeline without incorporating any bias based on gender, ethnicity or may result in an unfair advantage

***Azure ML can tell you how each feature can influence a model's prediction for bias***

**Fairlearn** is an open-source python project to help data scientist to improve fairness in their Al systems

### Responsible AI - Reliability and safety

***AI systems should perform reliably and safely***

AI software must be rigorous tested to ensure they work as expected before release to the end user

If there are scenarios where Al is making mistakes its important to release a report **quantified risks and harms** to end-users so they are informed of the short-comings of an AI solution

AI where concern for reliability and safety for humans is critically important:

* Autonomous Vehicle
* AI health diagnosis, AI suggesting prescriptions
* Autonomous Weapon Systems

### Responsible AI - Privacy and security

***AI systems should be secure and respect privacy***

AI can require vasts amounts of data to train Deep Learning ML models.

The nature of the ML model may require **personally identifiable information (PII)**

***It is important that we ensure protection of user data that it is not leaked or disclosed***


In some cases ML Models can be run locally on a user's device so their PII remains on their device avoiding that vulnerability

AI Security Principles to detect malicious actors:

* Data Origin and Lineage
* Data Use Internal vs External
* Data Corruption Considerations
* Anomaly detection

### Responsible AI - Inclusiveness

**AI systems should empower everyone and engage people**

If we can design AI solutions for the minority of users 

Then we can design AI solutions for the majority of users

**Minority Groups**

* physical ability
* gender
* sexual orientation
* ethnicity
* other factors

### Responsible AI - Transparency

**AI systems should be understandable**

Interpretability / Intelligibility is when end-users can understand the behaviour of the UI

Transparency of AI systems can result in

* Mitigating unfairness
* Help developers debug their AI systems
* Gaining more trust from our users

Those build AI systems should be:

* open about the why they are using AI
* open about the limitations of their AI systems

Adopting an open-source AI framework can provide transparency (at least from a technical perceptive) on the internal workings of an AI systems

### Responsible AI - Accountability

**People should be accountable for AI systems**

The structure put in place to consistently enacting AI principles and taking them into account

AI systems should work within:

* framework of governance
* organizational principles

ethical and legal standards that are clearly defined

Principles guide Microsoft on how they **Develop, Sell and Advocate** when working
with third-parties and this can push towards regulations towards Al Principles

## Guidelines for Human-AI Interaction

Microsoft has a free web-app that goes through practical scenarios to teach Microsoft Al Principle

![Alt Image Text](../images/ai102_1_14.png "Body image")

### Responsible AI Standard V2

**The Microsoft Responsible AI Standard** is **playbook** that organizations can use to **implement responsibility controls** to ensure governance of the AI Responsibility

![Alt Image Text](../images/ai102_1_15.png "Body image")

### AI Transparency Report

**Responsible AI (RAI) Transparency Report** is a **PDF Report** that outlines the steps the Microsoft has taken to be responsible with AI technologies.

The report includes:

* How they build GenAl: Govern, Map, Measure, Manage
* AI Customer Commitments
* Governance of Responsible AI at Microsoft
* and more ...

> AI Transparency Report is not an industry wide report and its just something Microsoft made up.

## Azure AI Services

**What is Azure AI Services?**

Azure AI Services is a consolidation of fully-managed, and serverless Azure
AI Services APIs.

When you create an Azure AI Service you don't need to create a resource for each targeted API. You use a **single key** for multiple endpoints.

You manage security, monitoring and automation from one interface.

![Alt Image Text](../images/ai102_1_16.png "Body image")

![Alt Image Text](../images/ai102_1_17.png "Body image")

### Azure AI Services Containers

**Azure AI Services Containers** allow you to **deploy a subset of AI service APIs via a container**.

Containers can be deployed to:

* Local Docker servers for on-premise workloads
* Azure Container Instances (ACI)
* Azure Kubernetes Service (AKS)

Step 1: Download the container image from the **Microsoft Container Registry**,

Step 2: Deploy the container image to your chosen container host.

Step 3: Configure the container with necessary settings (API key, billing endpoint, EULA acceptance).

![Alt Image Text](../images/ai102_1_18.png "Body image")

**Client Interaction**

* Client applications send data to the containerized service endpoint.
* The service processes the data and returns results to the client.

**Billing and Metrics**

* Usage metrics are periodically sent to Azure to calculate billing.
* Ensure the container can connect to the Azure AI services resource for this purpose.

### Available Azure AI Services containers

**Language Containers**

* **Key Phrase Extraction**: mcr.microsoft.com/azure-cognitive-services/textanalytics/keyphrase
* **Sentiment Analysis**: mcr.microsoft.com/azure-cognitive-services/textanalytics/sentiment
* **Translator**: mcr.microsoft.com/product/azure-cognitive-services/translator/text-translation/about


**Speech Containers**

* **Speech to Text**: mcr.microsoft.com/product/azure-cognitive-services/speechservices/speech-to-text/about
* **Neural Text to Speech**: mcr.microsoft.com/product/azure-cognitive-services/speechservices/neural-text-to-speech/about

**Vision Containers**

* **Read OCR:** mcr.microsoft.com/product/azure-cognitive-services/vision/read/about
* **Spatial Analysis**: mcr.microsoft.com/product/azure-cognitive-services/vision/spatial-analysis/about

### Configure Diagnostic Logging

**Enable Diagnostic Settings**

Configure diagnostic settings to send logs and metrics to various destinations like Log Analytics, Event Hubs, or Storage Accounts.

![Alt Image Text](../images/ai102_1_19.png "Body image")


**Enable Diagnostic Settings**

* Configure diagnostic settings to send logs and metrics
* to various destinations like Log Analytics, Event Hubs, or Storage Accounts.

**Select Log Categories**

Choose specific log categories to capture, such as
requests, errors, and performance metrics.

**Define Retention Policy**

Specify how long the logs and metrics should be
retained.

### View Diagnostic Logging

**Log Analytics**: Use Log Analytics to query and analyze logs. Create custom queries to filter and visualize data.

![Alt Image Text](../images/ai102_1_20.png "Body image")

**Capturing Diagnostic Data**

* It may take up to an hour or more for diagnostic data to start flowing to your specified destinations.
* Once the data is captured, it can be analyzed using Azure Log Analytics.

**Accessing Log Data**

* Navigate to your Azure Log Analytics resource in the Azure portal.
* Use the query editor to run queries against your log data.

## Monitor an Azure AI Resource

### Azure Monitor

**Azure Monitor**

* Integrate with Azure Monitor to set up alerts based on specific log or metric conditions.
* Centralized platform for collecting, analyzing, and acting on telemetry from Azure AI resources.

**Azure Metrics**

* **Request Count**: Track the number of API requests to the service.
* **Latency**: Measure the time taken to process requests.
* **Error Rates**: Monitor the frequency of errors and failures.
* **Resource Utilization**: Keep an eye on CPU, memory, and other resource usage.

**Event Hubs**

Stream logs to Event Hubs for real-time analytics and integration with third-party monitoring tools.

### Monitor an Azure AI Resource

Azure provides alerting support for resources through the creation of alert rules.

These rules ensure the correct team is notified when an issue arises.

#### **Defining the Alert Rule**

**Scope**: Specify the resource you want to monitor.

**Condition**: Define the trigger based on a signal type:

* **Activity Log**: An entry in the activity log created by an action performed on the resource (e.g.,
regenerating subscription keys).
* **Metric**: A metric threshold (e.g., number of errors exceeding 10 in an hour).

**Optional Actions**: Configure actions such as sending an email to an administrator or running an Azure Logic App to address the issue automatically.


**Alert Rule Details**: Provide a name for the alert rule and select the resource group.

### Add metrics to a dashboard

**Dashboard Overview**

* Combine multiple visualizations from different resources.
* Gain an overall view of Azure resource health and performance.

**Steps to Create a Dashboard**

* Select **Dashboard** in the Azure portal menu.
* Add up to 100 named dashboards.
* Add a range of tiles and visualizations.
* Include charts from the **Metrics** page.

**Monitoring Dashboards**

* Customize dashboards to visualize key metrics and alerts.
* Use them for real-time monitoring and historical analysis.

![Alt Image Text](../images/ai102_1_21.png "Body image")

## Azure AI Services vs Azure AI Studio

#### **Azure Open AI Services**

A resource that provides API access to allow you to
deploy and programmatically work with OpenAl LLM
models.

#### Azure AI Services

A collection of Azure AI Services APls intended to
be used programmatically via single API key.

#### Azure Open AI Studio

A GUI that provides an easy way to interact with
OpenAI Services API and Azure AI Services APIs

#### Azure AI Studio

A GUI that provides an easy way to interact with Azure AI Services, LLMs, Generative Images and more.

When you provision Azure AI Studio it will create
an Azure AI Service resource so it can programmatically interact with Azure API Services

* Similar to OpenAI Studio but: 
	* provides access to a wider range of IM models.
* allows you to scope workloads into projects.

### Azure OpenAI Service

**Azure OpenAI Service** is an API that allows you to deploy, use and manage multiple OpenAI's LLM models.

**The same python library** used to interact with
OpenAI's API allows also lets you interact via the
Azure OpenAI Service.

```
from openai import AzureOpenAI

endpoint = "https://###.openai.azure.com/'
deployment = "gpt-35-turbo'
api_key = "###"

client = AzureOpenAI(azure_endpoint=endpoint, api_key=api_key)

completion = client.chat.completions.create(
	model=deployment,
	messages=[
			{"roles":"system", "content": prompt_documenrt },
			{"roles":"user", "content": "Hello" },],
	max_tokens=800,
	temperature=0.7,
	temperature=0.7,
   top_p=0.95,
	...
)
```

In order to use an OpenAI LLM model you will need
to first deploy it within the Azure OpenAI Studio.

### Azure OpenAI Studio

Azure OpenAI Studio is a GUI for the Azure OpenAI Services

You can do the following in OpenAI Studio:

* View available models in the Model Catalog
* Use a Chat completion LLM Model
* Use a Completion model
* Generate images with Dalle
* Fine tune a select amount of models
* Upload data to be used for RAG

![Alt Image Text](../images/ai102_1_22.png "Body image")

## Azure OpenAI Services - Models

### **Chat Completion Models**

**GPT-3.5-Turbo-0125**

* An earlv version of GPT 3.5, better than GPT3
* Turbo because its optimized for performance
* 16K Context

**GPT-3.5-Turbo-Instruct**

Fine-tuned to to accept and return step by step instructions  4K Context

**GPT4**

* Better than GPT 3.5
* 128K Context

**GPT4 Turbo**

Faster, more cost effective variant with less reasoning capabilities 128K Context

**GPT4 Turbo Vision**

* MultiModal (Text and images) variant
* 128K Context

**GPT4o (omni)**

MultiModal (Text and images) with improved reasons and understanding 128K Context

**GPT4o-mini**

MonoModal (Text) trained

### Completion Models

* Babbage-002
* Davinci-002

> These were the early models of OpenAI, in the GPT3 series

* Small, less complex very fast for low compute 4K Context
* Largest and most complex of the GPT3 series ~4K Context

**Embedding Models**

* Ada
* Text-embedding-3-small
* Text-embedding-3-large

* GPT3 Family (old)
* Less complex embedding
* More complex embedding

**Speech-to-Text Models**

Whisper

**Text-to-Speech Models**

* TTS
* TTS-HD

**Image Models**

* Dall-e-2
* Dall-e-3

**Fine-Tuning Models**

* Babbage-002
* Davinci-002
* GPT-3.5-Turbo-Instruct
* GPT4o-mini

### Azure OpenAl Services - Deployment Types


When you deploy a model you may have varying deployment type available.

![Alt Image Text](../images/ai102_1_23.png "Body image")

## What is RAG?

#### **What is RAG?**

Retrieval-Augmented-Generation (RAG) is **access patterns for retrieving external data to inform an LLM agent** prior to providing a response to the user.

A common RAG pattern is representing information as vectors in a vector database and then
using a Search Engine to vectorize a search term to return relevant documents

![Alt Image Text](../images/ai102_1_24.png "Body image")

* Returned information is directly inserted into the context windows of an LLM.
* A RAG access pattern doesn't require a vector database
	* What's important to remember is if you have to fetch external data, than you are utilizing a RAG.

### What is Document Cracking?

**What is Document Cracking?**

* Document cracking is the **process of opening files and extracting content**.
* It's an alternative (and cooler sounding) term for ***Document Extraction***.
* When we say document we are not limiting to just text, could also be images or video.

![Alt Image Text](../images/ai102_1_25.png "Body image")

Various file mediums, and file formats the LLM can't understand

![Alt Image Text](../images/ai102_1_26.png "Body image")

**Parsers** are used to convert data into a format the the LLM can understand.

### What is HNSW?

**Hierarchical Navigable Small World (HNSW)** is a **graph-based algorithm** that performs Approximate Nearest Neighbor searches (ANN) in vector databases

* Skip Link Lists (SLL) is a data structure that lets you jump to farther away nodes
* Navigable Small Word (NSW) is graph structure to relate similar nodes. 
* SLL + NWS = HNSW

**HNSW is an efficient algorithm for querying a vector database.**

![Alt Image Text](../images/ai102_1_27.png "Body image")
