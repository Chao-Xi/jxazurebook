
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Jacob's Azure 103&900 教程">
      
      
        <meta name="author" content="Jacob Xi">
      
      
      
        <link rel="prev" href="../1ai900_ba/">
      
      
        <link rel="next" href="../3ai_900/">
      
      
      <link rel="icon" href="../../images/logo.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>2 Azure AI Fundamentals certification - Jacob Azure103&900 tutorial Book</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="light-blue" data-md-color-accent="light-blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#2-azure-ai-fundamentals-certification" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="Jacob Azure103&amp;900 tutorial Book" class="md-header__button md-logo" aria-label="Jacob Azure103&900 tutorial Book" data-md-component="logo">
      
  <img src="../../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Jacob Azure103&900 tutorial Book
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2 Azure AI Fundamentals certification
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/Chao-Xi/jxazurebook.git" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    jxazurebook
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Jacob Azure103&amp;900 tutorial Book" class="md-nav__button md-logo" aria-label="Jacob Azure103&900 tutorial Book" data-md-component="logo">
      
  <img src="../../images/logo.png" alt="logo">

    </a>
    Jacob Azure103&900 tutorial Book
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Chao-Xi/jxazurebook.git" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    jxazurebook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Welcome
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Azure Arch
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Azure Arch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../arch/1Well_arch_viw/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Azure Well Architecture Review
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    AZ103 Adv Tutorial（Eng)
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            AZ103 Adv Tutorial（Eng)
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap1/6az103_ad_sub_resource/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L1 Azure Administration: Manage Subscriptions and Resources
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap1/7az103_storage/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L2 Azure Administration: Implement and Manage Storage
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap1/8az103_Vms/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L3 Deploy and Manage Virtual Machines
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap1/9az103_vn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L4 Configure and Manage Virtual Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap1/10az103_ad/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L5 Azure Administration: Manage Identities
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap1/11az103_lb_ag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L6 Load Balancers and Application Gateways
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    AZ103 Adv Tutorial（Chn)
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            AZ103 Adv Tutorial（Chn)
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap2/12az_admin1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Azure Administrator认证学习 （1）
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap2/13az103_admin2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Azure Administrator认证学习 （2）
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap2/14az103_admin3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Azure Administrator认证学习 （3）
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Azure 103 interview
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Azure 103 interview
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap3/1az103_sub_resource/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L1 Manage Azure Subscriptions and Resources
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap3/2az103_storage_accounts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L2 Managing Azure storage
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap3/3az103_vms/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L3 Deploy and Manage Virtual Machines (VMs)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap3/4az103_VN/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L4 Configure and Manage Virtual Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap3/5az103_ad/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L5 Manage Identities
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap3/6azure_review/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    L6 Azure Review 103
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Azure 104 Test
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Azure 104 Test
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/1az_admin/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1 Azure Administration
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/2az_gc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2 Governance and Compliance
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/3indentity/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3 AZ Identity
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/4rbac/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4 Role-Based Access Control
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/5az_storage/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5 Azure Storage
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/6network/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6 Virtual Networking
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/7IntersiteConnectivity/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7 Intersite Connectivity
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/8vm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8 Azure Virtual Machines
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/9LB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9 Network Traffic Management
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/10webapp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10 Web Apps and Containers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/11monitor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11 Monitoring
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/12backup_dr/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12 Backup and Recovery
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/13summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13 AZ104 Gpt Summary
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/14exam_cheatsheet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Administrator Certification (AZ-104) CheatSheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/15exam_cheatsheet2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Administrator Certification (AZ-104) CheatSheet 2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/16cheatsheet_all/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Azure 104 CheatSheet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/17az104QA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AZ104 - 原题1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/18az104QA2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AZ104 - 原题2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/19az104QA3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AZ104 - 原题3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/20az103QA4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AZ104 - 原题 Summary
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az104/21az104Qs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Az104 final test
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Azure AI 102
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Azure AI 102
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ai102/1ai102/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Azure AI Engineer Associate Certification - AI102
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ai102/2ai102/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AI-102 Designing and Implementing a Microsoft Azure AI Solution
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Azure 305 test
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Azure 305 test
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az305/1az305/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1 Azure Solution Architect & Identity and Access Management
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az305/2az305/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2 Identity Security / Design a Compute Strategy
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az305/3az305/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3 Networking Strateg / Connectivity & Security
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az305/5az305_summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5 AZ305 Summary - 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az305/6za305_summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6 AZ305 Summary - 2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az305/7az305_summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7 AZ305 Summary - 3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az305/8az305_summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8 AZ305 Summary - 4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az305/9az305_summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9 AZ305 Summary - 5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az305/10az305_summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10 AZ305 Summary - 6
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az305/11az305_summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11 AZ305 Summary - 7
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az305/12az305_test1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12 AZ305 Test1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az305/az305_test2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13 AZ305 Test2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Azure 900 and int
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            Azure 900 and int
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap4/1az_900_int/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Az900 Fundamentals + Jam Azure Terraform
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap4/2azure_term_int/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Azure900 面试名词解释面试
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" checked>
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Azure AI 900
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            Azure AI 900
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1ai900_ba/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1 Azure AI Fundamentals Certification 2024 (AI-900)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    2 Azure AI Fundamentals certification
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    2 Azure AI Fundamentals certification
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-five-key-areas" class="md-nav__link">
    <span class="md-ellipsis">
      1 Five key areas:
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-introduction-to-azure-machine-learning" class="md-nav__link">
    <span class="md-ellipsis">
      2 Introduction to Azure Machine Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-overfitting" class="md-nav__link">
    <span class="md-ellipsis">
      3 OVERFITTING
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-cleaning-missing-data" class="md-nav__link">
    <span class="md-ellipsis">
      4 Cleaning missing data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-deploy-our-machine-learning-model-for-predictions" class="md-nav__link">
    <span class="md-ellipsis">
      5 Deploy our machine learning model for predictions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-and-deploying-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Training and deploying a model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adding-custom-code" class="md-nav__link">
    <span class="md-ellipsis">
      ADDING CUSTOM CODE
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#designing-solutions-using-azure-cognitive-services" class="md-nav__link">
    <span class="md-ellipsis">
      Designing Solutions Using Azure Cognitive Services
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#microsofts-vision-apis" class="md-nav__link">
    <span class="md-ellipsis">
      Microsoft's Vision APIs
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#microsoft-speech-services" class="md-nav__link">
    <span class="md-ellipsis">
      Microsoft Speech Services
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decision-and-web-search" class="md-nav__link">
    <span class="md-ellipsis">
      Decision and Web Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#innovations-in-ai-and-machine-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Innovations in AI and Machine Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#understanding-the-azure-openai-service" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding the Azure OpenAI Service
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#welcome-to-generative-ai" class="md-nav__link">
    <span class="md-ellipsis">
      WELCOME TO GENERATIVE AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openai-service" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI SERVICE
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openais-gpt-4-and-gpt-35" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI's GPT-4 and GPT-3.5
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openais-code-generation-models" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI's code generation models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openais-image-generation-models" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI's image generation models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ethical-implications-of-working-with-azure-openai" class="md-nav__link">
    <span class="md-ellipsis">
      Ethical implications of working with Azure OpenAI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computer-vision" class="md-nav__link">
    <span class="md-ellipsis">
      Computer Vision
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#responsible-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Responsible AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-learning-and-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Deep learning and Neural networks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#machine-learning-classification-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Machine learning classification techniques
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#object-detection" class="md-nav__link">
    <span class="md-ellipsis">
      Object detection
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#azure-ai-face-service" class="md-nav__link">
    <span class="md-ellipsis">
      Azure AI Face service
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Text analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conversational-language-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      Conversational language understanding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conversational-language-understanding-in-azure" class="md-nav__link">
    <span class="md-ellipsis">
      Conversational language understanding in Azure
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#translation-in-azure" class="md-nav__link">
    <span class="md-ellipsis">
      Translation in Azure
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-real-exam" class="md-nav__link">
    <span class="md-ellipsis">
      2 Real exam
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#topic-2" class="md-nav__link">
    <span class="md-ellipsis">
      Topic 2
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3ai_900/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3 AI900 Practice exam
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4ai_900/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4 Real Exam - Chap 3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5ai_900_sum/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5 AI900 Exam summary
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6sum_fin/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6 AI900 finaL SUMMARY
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Azure AZ 400
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Azure AZ 400
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az400/1az400_learn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1 Azure DevOps Engineer Expert Certification (AZ-400)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_12" >
        
          
          <label class="md-nav__link" for="__nav_12" id="__nav_12_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Azure DP900
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_12">
            <span class="md-nav__icon md-icon"></span>
            Azure DP900
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap5/dp1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Module 1 Explore core data
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap5/dp2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Module 2 Explore fundamental relational data concepts
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap5/dp3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Module 3 Non-relational data in Azure
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap5/dp4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Module 4 Large-scale data warehousing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap5/dp5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Module 5 data visualization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap5/dp900_qa/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DP900 Real Exam
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap5/dp900_learn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DP900 Learn (Cont.)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap5/dp900_sum/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DP900 Exam Points
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_13" >
        
          
          <label class="md-nav__link" for="__nav_13" id="__nav_13_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Azure UBS
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_13">
            <span class="md-nav__icon md-icon"></span>
            Azure UBS
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap6/1azure_hybird/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1 Implementing Hybrid Infrastructure
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap6/2azure_sla/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2 微软Azure高韧性
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chap6/3azure_hybird_conn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3 Hybrid Connectivity
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ubsaz/1azhci_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Azure Stack HCI 面向混合云和数据中心现代化的最佳基础设施
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ubsaz/2Migration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Azure Linux OSS Database Migration
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14" >
        
          
          <label class="md-nav__link" for="__nav_14" id="__nav_14_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Azure DevOps: Release Pipelines
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14">
            <span class="md-nav__icon md-icon"></span>
            Azure DevOps: Release Pipelines
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../devops/1release_mgmt/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1 Introduction to Release Management
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../devops/2iac/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2 Infrastructure as Code
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../devops/3secuirty/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3 Security, Approval, and Audit Trails
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../devops/4Devops_IAC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4 Azure DevOps的Azure资源IaC编排实战
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../devops/5Devops_go_host/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5 基于Azure Devops的Golang项目云主机CI/CD实战
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../devops/6Devops_go_container/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6 基于Azure DevOps的Golang项目容器化CI/CD实战
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_15" >
        
          
          <label class="md-nav__link" for="__nav_15" id="__nav_15_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Azure Monitoring
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15">
            <span class="md-nav__icon md-icon"></span>
            Azure Monitoring
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az_mon/1log_ana/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1 Microsoft Azure Log Analytics Workspace
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az_mon/2mon/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2 Azure Monitoring Fundamentals
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../az_mon/3mon_test/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3 Monitoring Microsoft Azure
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-five-key-areas" class="md-nav__link">
    <span class="md-ellipsis">
      1 Five key areas:
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-introduction-to-azure-machine-learning" class="md-nav__link">
    <span class="md-ellipsis">
      2 Introduction to Azure Machine Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-overfitting" class="md-nav__link">
    <span class="md-ellipsis">
      3 OVERFITTING
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-cleaning-missing-data" class="md-nav__link">
    <span class="md-ellipsis">
      4 Cleaning missing data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-deploy-our-machine-learning-model-for-predictions" class="md-nav__link">
    <span class="md-ellipsis">
      5 Deploy our machine learning model for predictions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-and-deploying-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Training and deploying a model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adding-custom-code" class="md-nav__link">
    <span class="md-ellipsis">
      ADDING CUSTOM CODE
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#designing-solutions-using-azure-cognitive-services" class="md-nav__link">
    <span class="md-ellipsis">
      Designing Solutions Using Azure Cognitive Services
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#microsofts-vision-apis" class="md-nav__link">
    <span class="md-ellipsis">
      Microsoft's Vision APIs
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#microsoft-speech-services" class="md-nav__link">
    <span class="md-ellipsis">
      Microsoft Speech Services
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decision-and-web-search" class="md-nav__link">
    <span class="md-ellipsis">
      Decision and Web Search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#innovations-in-ai-and-machine-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Innovations in AI and Machine Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#understanding-the-azure-openai-service" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding the Azure OpenAI Service
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#welcome-to-generative-ai" class="md-nav__link">
    <span class="md-ellipsis">
      WELCOME TO GENERATIVE AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openai-service" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI SERVICE
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openais-gpt-4-and-gpt-35" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI's GPT-4 and GPT-3.5
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openais-code-generation-models" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI's code generation models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openais-image-generation-models" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI's image generation models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ethical-implications-of-working-with-azure-openai" class="md-nav__link">
    <span class="md-ellipsis">
      Ethical implications of working with Azure OpenAI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#computer-vision" class="md-nav__link">
    <span class="md-ellipsis">
      Computer Vision
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#responsible-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Responsible AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-learning-and-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Deep learning and Neural networks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#machine-learning-classification-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Machine learning classification techniques
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#object-detection" class="md-nav__link">
    <span class="md-ellipsis">
      Object detection
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#azure-ai-face-service" class="md-nav__link">
    <span class="md-ellipsis">
      Azure AI Face service
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Text analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conversational-language-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      Conversational language understanding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conversational-language-understanding-in-azure" class="md-nav__link">
    <span class="md-ellipsis">
      Conversational language understanding in Azure
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#translation-in-azure" class="md-nav__link">
    <span class="md-ellipsis">
      Translation in Azure
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-real-exam" class="md-nav__link">
    <span class="md-ellipsis">
      2 Real exam
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#topic-2" class="md-nav__link">
    <span class="md-ellipsis">
      Topic 2
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="2-azure-ai-fundamentals-certification">2 Azure AI Fundamentals certification</h1>
<p>Learning Objectives</p>
<ul>
<li>Describe AI workloads and considerations</li>
<li>Describe fundamental principles of machine learning on Azure</li>
<li>Describe features of computer vision workloads on Azure</li>
<li>Describe features of Natural Language Processing (NLP) workloads on Azure</li>
<li>Describe features of conversational AI workloads on Azure</li>
</ul>
<h3 id="1-five-key-areas">1 Five key areas:</h3>
<ul>
<li>AI workloads </li>
<li>Fundamental principles of machine learning on Azure, features of computer vision workloads on Azure, </li>
<li>Features of natural language processing workloads on Azure, </li>
<li>Features of generative AI workloads on Azure.</li>
</ul>
<p><strong>INTRODUCTION TO AZURE MACHINE LEARNING</strong></p>
<p>Let's start with an introduction to Azure Machine Learning designer, a drag-and-drop interface for training and deploying machine learning models without writing any code.</p>
<p>You'll learn about the fundamentals of machine learning, data preparation, and model evaluation, covering classification, regression, and clustering</p>
<p><strong>AZURE AI SERVICES SUITE</strong></p>
<p>Next, we'll explore the Azure AI services suite, a collection of pre-built AI components.</p>
<p>We'll delve into its computer vision capabilities, natural language processing capabilities, and the
Azure OpenAI Service, which allows you to create applications using OpenAI's generative AI models</p>
<h3 id="2-introduction-to-azure-machine-learning">2 Introduction to Azure Machine Learning</h3>
<p><strong>HOW MACHINE LEARNING WORKS</strong></p>
<p>Machine learning is transforming industries, from cybersecurity to customer service </p>
<p>At its core, its about feeding real-world data into a program to make predictions.</p>
<p>For example, it can analyze emails to predict if they're spam or not.</p>
<p><strong>CREATING AN AZURE MACHINE LEARNING WORKSPACE</strong></p>
<p>To get started, we'll create an Azure Machine Learning workspace.</p>
<p>In the Azure portal, we'll set up a workspace and a compute target to run our machine learning experiment.</p>
<p><strong>EVALUATING THE MODEL</strong></p>
<p>After training the model, we'll use the <strong>Score Model and Evaluate Model modules</strong> to see how accurate our predictions are.</p>
<h3 id="3-overfitting">3 OVERFITTING</h3>
<p>Lets say We built a model with 98% accuracy, which sounds impressive, but there's a catch.</p>
<ul>
<li><strong>WHAT IS OVERFITTING?</strong></li>
</ul>
<p>The problem is that we used the same data to evaluate the model that we used to train it.</p>
<p><strong>This can lead to overfitting, where the model perfectly fits the training data but performs poorly with new data</strong>.</p>
<ul>
<li><strong>HOW TO AVOID OVERFITTING</strong></li>
</ul>
<p>One critical way to reduce the risk of overfitting is to evaluate the model using a separate test dataset.</p>
<p><strong>By splitting the original dataset into a training dataset (70-80%) and a test dataset (20-30%)</strong>, we can effectively identify overfitting issues.</p>
<p><strong>IMPLEMENTING THE SOLUTION</strong></p>
<p>In the "Data Transformation" section, find the "Split Data" module and adjust the settings to create an 80/20 split.</p>
<p>Then, connect the dataset to the Split Data module and proceed to evaluate the model.</p>
<p>By evaluating the model using data that it didn't see during the training phase, we were able to identify and address the overfitting problem.</p>
<p>Remember, accurate evaluation is key in machine learning.</p>
<h3 id="4-cleaning-missing-data">4 Cleaning missing data</h3>
<p>Let's dive into cleaning missing data to see how it can boost your model's performance.</p>
<ul>
<li><strong>IDENTIFYING MISSING DATA</strong></li>
</ul>
<p>First, let's identify the missing data.</p>
<p>We'll explore the dataset and find columns with missing values, like the 'normalized-losses' and 'price' columns.</p>
<p><strong>CLEANING PROCESS</strong></p>
<p>Next, we'll clean the data using modules like <strong>'Select Columns in Dataset' and 'Clean Missing Data</strong>'.</p>
<p>We'll exclude the 'normalized-losses' column and remove rows with missing prices.</p>
<p><strong>RESULTS</strong></p>
<p>After running the pipeline, the accuracy jumped from 93.5% to 95.1%!</p>
<p><strong>It's clear that cleaning missing data can significantly enhance your model's accuracy.</strong></p>
<p>Experimenting with different cleaning methods is key to finding the best approach for your model.</p>
<h3 id="5-deploy-our-machine-learning-model-for-predictions">5 Deploy our machine learning model for predictions</h3>
<p><strong>CREATING THE INFERENCE PIPELINE</strong></p>
<ul>
<li>To get started, we'll create a <strong>real-time inference pipeline.</strong></li>
<li><strong>This will allow us to submit new data and receive predictions in real-time</strong>.</li>
</ul>
<p><strong>SETTING UP THE DEPLOYMENT TARGET</strong></p>
<ul>
<li>Next, we'll create a deployment target, a <strong>compute cluster that will run the inference pipeline</strong>.</li>
<li>We'll select the region and virtual machine size suitable for our needs.</li>
</ul>
<p><strong>DEPLOYING THE MODEL</strong></p>
<ul>
<li>After creating the inference cluster, we'll deploy the real-time inference pipeline to it.</li>
<li>
<p>This may take a while, but once it's ready, we can move on to testing.</p>
</li>
<li>
<p><strong>TESTING THE MODEL</strong></p>
</li>
<li>
<p>In the testing phase, we'll input new data or use the automatically filled fields to see the model's predictions.</p>
</li>
<li>Once satisfied, we'll learn how to call the endpoint from our applications.</li>
</ul>
<h3 id="training-and-deploying-a-model">Training and deploying a model</h3>
<p>Let's dive into the different compute and deployment targets you can choose from to optimize your model's performance.</p>
<ul>
<li><strong>COMPUTE TARGETS</strong></li>
</ul>
<p>When training a model, you have the choice of <strong><mark>compute instances, compute clusters, and attached compute</mark></strong>.</p>
<p>Compute instances are individual virtual machines, with the option to select the size and type of processing unit - CPUs or GPUs.</p>
<p><strong>GPUs are particularly beneficial for deep learning models due to their ability to perform a large number of computations simultaneously.</strong></p>
<p>If a single compute instance isn't fast enough, a compute cluster, such as an Azure Kubernetes Service cluster, can be utilized for scalability.</p>
<ul>
<li><strong>DEPLOYMENT TARGETS</strong></li>
</ul>
<p>For deployment, the default option in the Machine Learning Designer is an Azure Kubernetes Service cluster.</p>
<p>However, <strong>if using the Azure Machine Learning SDK, numerous other options are available, including Azure Container Instances, Azure Functions, and Azure IoT Edge</strong>.</p>
<p>And that's a wrap on the various compute and deployment targets you can leverage for your model training and deployment.</p>
<h3 id="adding-custom-code">ADDING CUSTOM CODE</h3>
<p>Learn how to add custom code to your Azure Machine Learning pipelines using the "Execute Python Script" module.</p>
<p><strong>CUSTOM CODE</strong></p>
<p>To add your own code to a pipeline, you can use the "Execute Python Script" module.</p>
<p>This module allows you to import additional Python resources via a zip bundle and has two output ports for results datasets.</p>
<p><strong>FLEXIBILITY</strong></p>
<p>You have the flexibility to input and output data using your Python code.</p>
<p>For instance, you can send output directly to Azure Storage.</p>
<p><strong>However, if you're building a pipeline with multiple modules, you'll need to use at least one input and one output port</strong>.</p>
<p><strong>DEVELOPMENT ENVIRONMENT</strong></p>
<p>Remember, the Designer doesn't provide tools for development and debugging, </p>
<p>so it's recommended to do your development in a different environment and then paste the code into the module.</p>
<h3 id="designing-solutions-using-azure-cognitive-services">Designing Solutions Using Azure Cognitive Services</h3>
<p><strong>WHAT ARE COGNITIVE SERVICES?</strong></p>
<p>Cognitive Services allow developers to build AI-infused applications without needing AI, ML, or Data Sciences skills.</p>
<p>It's like having Machine Learning as a Service, providing a huge head start by utilizing refined technologies from Microsoft.</p>
<p><strong>KEY FEATURES</strong></p>
<p>Cognitive Services offer a wide language support, keep your data private, and are generally inexpensive to consume.</p>
<p>Plus, many services have a free tier to get you started without an Azure subscription.</p>
<p><strong>VARIATIONS AND PILLARS</strong></p>
<p><strong>With over 20 services divided into 5 pillars, including Vision, Speech, Language, Decision, and Web Search, Cognitive Services cover a wide range of AI capabilities</strong>.</p>
<p><strong>CONCLUSION</strong></p>
<p>Cognitive Services are a fast-evolving part of Microsoft's AI strategy, constantly changing and improving.</p>
<h3 id="microsofts-vision-apis">Microsoft's Vision APIs</h3>
<p><strong>COMPUTER VISION</strong></p>
<p>Microsoft's Computer Vision API is a versatile tool that can describe images, identify objects, detect faces, and even extract text from images.</p>
<p>It can also recognize colors, identify adult content, and even celebrities and  dlandmarks.</p>
<ul>
<li><strong>FACE API</strong></li>
</ul>
<p>The Face API is specialized for facial recognition and detection.</p>
<p>It can identify emotions, generate face landmarks, and even create a persons group for face recognition and authentication.</p>
<ul>
<li><strong>VIDEO INDEXER</strong></li>
</ul>
<p>For video files, the Video Indexer API is the go-to tool.</p>
<p>It can identify people, create subtitles, detect sentiment, and generate keywords for better indexing.</p>
<ul>
<li><strong>CUSTOM VISION</strong></li>
</ul>
<p>Custom Vision allows you to train the Vision model to your specific needs, making it a powerful tool for custom image recognition and classification.</p>
<p>Microsoft's Vision APIs offer a wide range of capabilities, from general image analysis to specialized facial recognition and custom model </p>
<h3 id="microsoft-speech-services">Microsoft Speech Services</h3>
<ul>
<li><strong>SPEECH SERVICES OVERVIEW</strong></li>
</ul>
<p>Microsoft's Speech Services API offers <strong>Speech-to-Text, Text-to-Speech, and Speech Translation functionalities, all in one comprehensive package</strong>.</p>
<p>This technology is highly mature, low latency, and natively integrated into the Bot Framework for seamless voice interactions.</p>
<ul>
<li><strong>LANGUAGE SUPPORT</strong></li>
</ul>
<p>The service supports 40 languages for Speech-to-Text, 45 languages for Text-to-Speech with 75 voices, and 60 languages for Speech Translation, including Klingon for the Star Trek fans out there.</p>
<ul>
<li><strong>SPEAKER RECOGNITION</strong></li>
</ul>
<p>Speaker Recognition allows for voice-based authentication, similar to face recognition, with an enrollment phase to create a unique voice signature.</p>
<ul>
<li><strong>SPEECH-TO-TEXT FEATURES</strong></li>
</ul>
<p>The speech-to-Text service offers profanity handling, three recognition modes, and JSON response types, making it versatile for various applications.</p>
<ul>
<li><strong>CONNECTING TO THE SERVICE</strong></li>
</ul>
<p>Connecting to Speech-to-Text can be done <strong>via REST API, Batch Transcription API, Speech SDKs, or Speech Devices SDK, each with its own unique advantages</strong>.</p>
<ul>
<li><strong>TEXT-TO-SPEECH FEATURES</strong></li>
</ul>
<p>Text-to-Speech offers standard and neural voices, as well as the ability to create custom voice models using Custom Speech.</p>
<ul>
<li><strong>SPEECH TRANSLATION</strong></li>
</ul>
<p>Speech Translation leverages the Translation Text API and is available through the SDK, offering options to handle profanity in translated text.</p>
<ul>
<li><strong>CUSTOM SOLUTIONS</strong></li>
</ul>
<p>Customizing Speech Services is made easy with Speech Studio, allowing for the creation of acoustic models, language models, custom pronunciation models, and even personalized voice fonts.</p>
<p>Microsoft Speech Services opens up a world of possibilities for voice-enabled applications.</p>
<h3 id="decision-and-web-search">Decision and Web Search</h3>
<ul>
<li>
<p><strong>DECISION CATEGORY</strong></p>
</li>
<li>
<p>In the Decision category, we have two powerful options.</p>
</li>
<li>
<p>The Content Moderator, which ensures user-generated content is appropriate, and the Personalizer, a cloud-based API for tailoring content to specific users.</p>
</li>
<li>
<p><strong>WEB SEARCH CATEGORY</strong></p>
</li>
</ul>
<p>Now, let's talk about the last pillar of Cognitive Services - Web Search.</p>
<p>This category includes Bing Web, Video, Image, and News Search, all falling under the Bing umbrella.</p>
<ul>
<li><strong>BING SERVICES</strong></li>
</ul>
<p>Let's explore the unique Bing services, such as Bing Spell Check, Bing Autosuggest, Bing Entity Search, Bing Visual Search, and Custom Search.</p>
<p>Each of these services offers a distinct and valuable function for your applications.</p>
<p>With these incredible tools, you can take your applications to the next level, providing tailored content and seamless web search experiences.</p>
<h3 id="innovations-in-ai-and-machine-learning">Innovations in AI and Machine Learning</h3>
<p><strong>ADVANCEMENTS IN AI</strong></p>
<p>Cutting-edge technology now allows computers to learn, interact, and reason in unprecedented ways, thanks to advancements in Cloud, Computing, and Data</p>
<p><strong>MICROSOFT'S COGNITIVE SERVICES.</strong></p>
<p>Microsoft's Cognitive Services, including Vision, Speech, Language, Decision, and Web Search, offer accessible AI models for various applications, from recognizing objects to enabling apps to listen and speak.</p>
<h3 id="understanding-the-azure-openai-service">Understanding the Azure OpenAI Service</h3>
<ul>
<li><strong>WHAT IS GENERATIVE AI?</strong></li>
</ul>
<p>Generative AI is a fascinating concept that we'll explore, and we'll delve into where the OpenAI models fit into the broader AI landscape.</p>
<ul>
<li><strong>AZURE OPENAI SERVICE CAPABILITIES</strong></li>
</ul>
<p>Discover the different capabilities of the Azure OpenAI service, including its natural language, code generation, and image generation capabilities.</p>
<ul>
<li><strong>ACCESS AND RESPONSIBLE AI POLICIES</strong></li>
</ul>
<p>We'll wrap things up by reviewing Azure OpenAI's access and responsible AI policies, ensuring a comprehensive understanding of what the service offers.</p>
<h3 id="welcome-to-generative-ai">WELCOME TO GENERATIVE AI</h3>
<p>diving into the transformative capabilities of OpenAI and its ground breaking technologies like ChatGPT and DALL-E.</p>
<p><strong>These AI models can take natural language input and return human-like responses, making them incredibly versatile tools in the AI landscape.</strong></p>
<ul>
<li><strong>OPENAI'S GENERATIVE AI CAPABILITIES</strong></li>
</ul>
<p>OpenAI's generative AI models can generate natural language, code, and images, performing tasks like summarizing text, suggesting alternative wording, translating code, and creating realistic or artistic images.</p>
<p>These models, such as GPT-3.5 and GPT-4, excel at a variety of natural language tasks and are at the heart of OpenAI's capabilities.</p>
<ul>
<li><strong>THE POWER OF GPT MODELS</strong></li>
</ul>
<p>GPT models, like GPT-3.5 and GPT-4, are adept at inferring the context of a user's question based on the prompt, allowing them to answer questions, generate names or phrases, and much more.</p>
<p>They are incredibly versatile and can be applied to various use cases, shaping the future of AI.</p>
<ul>
<li><strong>GENERATIVE AI IN ACTION</strong></li>
</ul>
<p>For example, a GPT model can generate a detailed cooking recipe based on certain ingredients.</p>
<p>However, it's important to remember that the responses generated are best guesses from a machine, and should be reviewed for accuracy.</p>
<p>In essence, OpenAI's generative AI models are powerful tools that can produce new content based on the input they receive, shaping the future of AI and its applications across various industries</p>
<h3 id="openai-service">OpenAI SERVICE</h3>
<p>Leveraging Azure's infrastructure, including security, compliance, and regional availability, this service is designed to assist users in developing enterprise-grade applications.</p>
<ul>
<li><strong>AZURE OPENAI SERVICE COMPONENTS</strong></li>
</ul>
<p>The Azure OpenAI Service consists of pre-trained generative AI models, customization capabilities, built-in tools to detect and mitigate harmful use cases, and enterprise-grade security with role-based access control (RBAC) and private networks.</p>
<ul>
<li><strong>WIDE ARRAY OF AI WORKLOADS</strong></li>
</ul>
<p>From machine learning to conversational AI and knowledge mining, Azure OpenAI supports a wide array of AI workloads, making it a versatile tool for developers.</p>
<ul>
<li><strong>AZURE OPENAI STUDIO</strong></li>
</ul>
<p>Explore the Azure OpenAI Studio, a platform where you can build and deploy AI models for public consumption in software applications.</p>
<p>Whether it's generating code or unique images from text input, the studio has you covered.</p>
<ul>
<li><strong>ACCESSING AZURE OPENAI</strong></li>
</ul>
<p>Accessing Azure OpenAI requires an application process.</p>
<p>Once granted access, you can use the service through REST APIs, Python SDK, or the web-based interface in the Azure OpenAI Studio.</p>
<h3 id="openais-gpt-4-and-gpt-35">OpenAI's GPT-4 and GPT-3.5</h3>
<p><strong>UNDERSTANDING THE MODELS</strong></p>
<p>OpenAI's GPT-4 and GPT-3.5 are trained on a diverse range of internet text and excel at tasks like summarizing, classifying, translating, answering questions, and generating content.</p>
<p><strong>TOKENS AND TRAINING</strong></p>
<p>These models break down input into tokens and map them into vectors for machine-learning training, allowing them to understand and generate natural language.</p>
<p><strong>PREDICTIVE CAPABILITIES</strong></p>
<p>Developers have integrated these models into various applications, such as ChatGPT, where users can interact with generative AI capabilities through a front-end user interface.</p>
<p>Remember, while these models provide impressive responses, they are ultimately best guesses from a machine.</p>
<h3 id="openais-code-generation-models">OpenAI's code generation models</h3>
<p>Exciting advancements in AI have led to the development of OpenAI's code generation models, including GPT-4 and GPT-3.5-Turbo.</p>
<p>These models are revolutionizing the way we interact with programming languages and code snippets.</p>
<ul>
<li><strong>UNDERSTANDING THE MODELS</strong></li>
</ul>
<p>OpenAI's code generation AI models, such as GPT-4 and GPT-3.5- Turbo, are proficient in over a dozen languages, including Python, C#, JavaScript, Perl, and PHP.</p>
<p>They work by breaking down input into tokens and mapping them into vectors for machine-learning model training.</p>
<ul>
<li><strong>GENERATING CODE</strong></li>
</ul>
<p>These models can generate code based on natural language prompts.</p>
<p>For example, they can accurately produce a Python function that adds two numbers when given the prompt.</p>
<p>However, it's important to note that while the generated code is syntactically correct, it may not always be logically correct or optimal.</p>
<ul>
<li><strong>APPLICATION IN DEVELOPMENT</strong></li>
</ul>
<p>Developers have integrated these code generation capabilities into front-end user interfaces, allowing users to type prompts and receive automated code snippets.</p>
<p>This integration is available through the OpenAI API and Azure OpenAI API, providing a powerful tool for developers.</p>
<p>OpenAI's code generation models are transforming the landscape of programming and development, offering innovative solutions for code generation and language understanding.</p>
<h3 id="openais-image-generation-models">OpenAI's image generation models</h3>
<p>Discover the incredible capabilities of OpenAI's image generation models, like DALL-E, which can create new images based on prompts, base images, or both.</p>
<p><strong>IMAGE CREATION</strong></p>
<p>OpenAI's DALL-E can <strong>generate original images by interpreting detailed text prompts</strong>.</p>
<p>For example, a prompt for a 'futuristic cityscape at sunset' can result in a visually accurate representation.</p>
<p><strong>EDITING AND VARIATIONS</strong></p>
<p>These generative AI models can also edit images, change layouts or styles, and create variations of provided images.</p>
<p>The possibilities are endless.</p>
<p><strong>IMPORTANT CONSIDERATION</strong></p>
<p>It's important to remember that the generated images are best guesses from a machine.</p>
<p>While they can visually represent the prompt, accuracy and optimization are not guaranteed.</p>
<h3 id="ethical-implications-of-working-with-azure-openai">Ethical implications of working with Azure OpenAI</h3>
<p><strong>PRINCIPLES OF ETHICAL AI</strong></p>
<p>When working with Azure OpenAI, it's crucial to adhere to the six Microsoft AI principles: <strong>fairness, reliability and safety, privacy and security, inclusiveness, accountability, and transparency</strong>.</p>
<p>These principles ensure that AI systems don't discriminate, respond safely to new situations, respect data privacy, <strong>empower everyone, hold people accountable, and provide explanations for user understanding</strong>.</p>
<p><strong>RESPONSIBLE USE AND ACCESS</strong></p>
<p>To ensure responsible use, access to Azure OpenAI is currently limited.</p>
<p>Customers must submit a registration form for initial experimentation access and approval for production use.</p>
<p>Additional registration is required for modifying content filters or abuse monitoring settings.</p>
<p>Working with Azure OpenAI comes with great potential, but it's essential to navigate it responsibly.</p>
<h3 id="computer-vision">Computer Vision</h3>
<p>Are you looking to develop computer vision solutions?</p>
<p>Look no further than Microsoft's Azure AI Vision in Azure Vision Studio.</p>
<p><strong>AZURE AI VISION FEATURES</strong></p>
<p>Explore the capabilities of <strong>Azure AI Vision, including image analysis, face detection and recognition, and optical character recognition (OCR)</strong>.</p>
<ul>
<li><strong>Image Analysis</strong>: capabilities for analyzing images and video, and extracting descriptions, tags, objects, and text.</li>
<li><strong>Face</strong>: capabilities that enable you to build face detection and facial recognition solutions.</li>
<li><strong>Optical Character Recognition (OCR)</strong>: capabilities for extracting printed or handwritten text from images, enabling access to a digital version of the scanned text.</li>
</ul>
<h3 id="responsible-ai">Responsible AI</h3>
<p>Lets explore the key principles that guide AI's software development at Microsoft.</p>
<p><strong>FAIRNESS</strong></p>
<p>First, let's talk about fairness.</p>
<p><strong>AI systems should treat all people fairly.</strong></p>
<p>For example, when creating a machine learning model for a loan approval application, it should predict loan approval without bias based on gender, ethnicity, or other factors.</p>
<p>Azure Machine Learning includes the <strong>capability to interpret models and quantify the extent of bias, helping to identify and mitigate it</strong>.</p>
<p><strong>RELIABILITY AND SAFETY</strong></p>
<p>Next, reliability and safety are crucial.</p>
<p>AI systems must perform reliably and safely, especially in applications like autonomous vehicles or medical diagnosis.</p>
<p>Rigorous testing and deployment management processes are essential to ensure these systems work as expected.</p>
<p><strong>PRIVACY AND SECURITY</strong></p>
<p>Privacy and security are also key.</p>
<p>AI systems should be secure and respect privacy, especially when dealing with large volumes of personal data.</p>
<p>Even after deployment, privacy and security concerns must be considered.</p>
<p><strong>INCLUSIVENESS</strong></p>
<p>Inclusiveness is another important principle.</p>
<p><strong>AI systems should empower everyone and bring benefits to all parts of society, regardless of physical ability, gender, or ethnicity.</strong></p>
<p><strong>TRANSPARENCY</strong></p>
<p>Transparency is crucial.</p>
<p>Users should be fully aware of the <strong>purpose of the system</strong>, how it works, and its limitations.</p>
<p><strong>ACCOUNTABILITY</strong></p>
<p>Lastly, accountability is essential.</p>
<p>Designers and developers of AI-based solutions should work within a framework of governance and organizational principles to ensure ethical and legal standards are met.</p>
<h3 id="deep-learning-and-neural-networks">Deep learning and Neural networks</h3>
<p><strong>UNDERSTANDING DEEP LEARNING</strong></p>
<p>Deep learning is an advanced form of machine learning that emulates the way the human brain learns.</p>
<p>It involves creating artificial neural networks that simulate electrochemical activity in biological neurons using mathematical functions.</p>
<p><strong>APPLICATION IN CLASSIFICATION</strong></p>
<p>For example, a deep neural network can be used to classify penguin species based on measurements of their bill length, bill depth, flipper length, and weight.</p>
<p>This demonstrates how deep learning can be applied to solve classification problems.</p>
<p><strong>TRAINING PROCESS</strong></p>
<p>During the training process, <strong>the model learns the weights that result in the most accurate predictions by iteratively adjusting the weights to minimize the loss</strong>.</p>
<p>Deep learning and neural networks are powerful tools for solving complex machine learning problems.</p>
<p>They have applications in various fields, including natural language processing and computer vision.</p>
<h3 id="machine-learning-classification-techniques">Machine learning classification techniques</h3>
<p>Do you know how machine learning classification techniques work?</p>
<p>Let's dive in and understand how they predict which category something belongs to.</p>
<p><strong>MACHINE LEARNING CLASSIFICATION</strong></p>
<p>Machine learning classification models use a set of inputs, called features, <strong>to calculate a probability score for each possible class and predict a label that indicates the most likely class that an object belongs to.</strong></p>
<p><strong>IMAGE CLASSIFICATION</strong></p>
<p>In image classification, <strong>digital images are used as features to train the model based on known image classes</strong>.</p>
<p>The model is then trained to match the patterns in the pixel values to a set of class labels.</p>
<p><strong>AZURE'S CUSTOM VISION SERVICE</strong></p>
<p>Azure's Custom Vision service in Microsoft Azure encapsulates common techniques used to train image classification models, making it easy to train a model and publish it as a software service with minimal knowledge of deep learning techniques.</p>
<h3 id="object-detection">Object detection</h3>
<p><strong>WHAT IS OBJECT DETECTION?</strong></p>
<p><strong>Object detection is a form of computer vision that goes beyond image classification.</strong></p>
<p>It identifies individual objects within an image and provides the class of each object, the probability score of the classification, and the coordinates of a bounding box for each object.</p>
<p><strong>OBJECT DETECTION VS Image Classification</strong></p>
<p>While image classification categorizes images based on primary subject matter, object detection takes it a step further by classifying individual objects within the image and providing their location coordinates.</p>
<p>It's a powerful tool in the world of computer vision.</p>
<h3 id="azure-ai-face-service">Azure AI Face service</h3>
<p><strong>WHAT IS THE AZURE AI FACE SERVICE?</strong></p>
<p>The Azure AI Face service provides AI algorithms that detect, recognize, and analyze human faces in images.</p>
<p>This technology is crucial for various scenarios, such as identification, touchless access control, and face blurring for privacy.</p>
<p><strong>HOW TO USE THE AZURE AI FACE SERVICE</strong></p>
<p>The Azure AI Face service provides AI algorithms that detect, recognize, and analyze human faces in images.</p>
<p>This technology is crucial for various scenarios, such as identification, touchless access control, and face blurring for privacy.</p>
<p><strong>HOW TO USE THE AZURE AI FACE SERVICE</strong></p>
<p>You can access the Face service through a client library SDK or by calling the REST API directly.</p>
<p>Plus, you can quickly try out its capabilities in your browser using Vision Studio.</p>
<p><strong>EXAMPLE USE CASES</strong></p>
<p>The service has a wide range of applications, from verifying user identity to enabling touchless access control and face redaction for privacy protection.</p>
<p><strong>CAUTION AND DATA PRIVACY</strong></p>
<p>It's important to note that Face service access is limited based on eligibility and usage criteria to support Responsible AI principles.</p>
<p>Also, data privacy and security are paramount, so be sure to review Microsoft's policies on customer data.</p>
<h3 id="text-analysis">Text analysis</h3>
<p><strong>NAMED ENTITY RECOGNITION</strong></p>
<p>Azure AI Language's text analysis features include named entity recognition, which identifies people, places, events, and more.</p>
<p>It can even be customized to extract custom categories.</p>
<p><strong>LANGUAGE DETECTION</strong></p>
<p>The language detection capability can identify the language in which text is written, providing the language name, ISO 639-1 language code, and a confidence score.</p>
<p><strong>SENTIMENT ANALYSIS</strong></p>
<p>The text analvtics capabilities can evaluate text and return sentiment scores and labels for each sentence, useful for detecting positive and negative sentiment in various contexts.</p>
<p><strong>KEY PHRASE EXTRACTION</strong></p>
<p>Key phrase extraction identifies the main points from text, providing a summary of the most important information.</p>
<h3 id="conversational-language-understanding">Conversational language understanding</h3>
<ul>
<li><strong>CORE CONCEPTS</strong></li>
</ul>
<p>To work with conversational language understanding, you need to take into account three core concepts: <strong>utterances, entities, and intents</strong>.</p>
<ul>
<li><strong>UTTERANCES</strong></li>
</ul>
<p>An utterance is an example of something a user might say, and which your application must interpret.</p>
<p>For example, when using a home automation system, a user might use the following: "Switch the fan on" or "Turn on the light."</p>
<p><strong>ENTITIES</strong></p>
<p>An entitv is an item to which an utterance refers.</p>
<p>For example, "fan" and "light" are entities in the utterances "Switch the fan on" and "Turn on the light."</p>
<p><strong>INTENTS</strong></p>
<p>An intent represents the purpose, or goal, expressed in a user's utterance.</p>
<p>For example, the intent for the utterances "Switch the fan on" and "Turn on the light" is to turn a device on.</p>
<p>After defining the entities and intents with sample utterances in your conversational language understanding application, you can train a language model to predict intents and entities from user input - even if it doesn't match the sample utterances exactly.</p>
<h3 id="conversational-language-understanding-in-azure">Conversational language understanding in Azure</h3>
<p><strong>AUTHORING A MODEL</strong></p>
<p>To begin, you'll define entities, intents, and utterances as part of authoring a model.</p>
<p>This step sets the foundation for generating predictions and creating a robust language understanding model.</p>
<p><strong>TRAINING THE MODEL</strong></p>
<p>Once the model is defined, the next step is training.</p>
<p>This process involves using sample utterances to teach the model to recognize natural language expressions and match them to probable intents and entities.</p>
<p>Training and testing is an iterative process, ensuring the model is fine-tuned for accuracy.</p>
<p><strong>PREDICTING</strong></p>
<p>After successful training and testing, it's time to publish your Conversational Language Understanding application to a prediction resource for consumption.</p>
<p>Client applications can then connect to the endpoint and submit user input to receive predicted intents and entities.</p>
<p>With Azure AI Language's conversational language understanding, you can build apps with industry-leading natural language understanding capabilities without machine learning expertise.</p>
<h3 id="translation-in-azure">Translation in Azure</h3>
<p><strong>AZURE AI TRANSLATOR</strong></p>
<p>Azure AI Translator supports text-to-text translation between more than 60 languages.</p>
<p><strong>It uses a Neural Machine Translation (NMT) model for more accurate and complete translations.</strong></p>
<p>Plus, you can fine-tune results with optional configurations like profanity filtering and selective translation.</p>
<p><strong>AZURE AI SPEECH</strong></p>
<p>With Azure AI Speech, you can transcribe speech to text, generate spoken audio from text, and even translate speech in real-time.</p>
<p>This service supports over 60 languages and enables scenarios like real-time closed captioning and two-way translation of spoken conversations</p>
<h2 id="2-real-exam">2 Real exam</h2>
<p>1) You build a machine learning model by using the automated machine learning user interface (UI).</p>
<p>You need to ensure that the model meets the Microsoft <strong>transparency</strong> principle for responsible AI.</p>
<p>What should you do?</p>
<ul>
<li>A. Set Validation type to Auto.</li>
<li><strong>B. Enable Explain best model.</strong></li>
<li>C. Set Primary metric to accuracy.</li>
<li>D. Set Max concurrent iterations to 0.</li>
</ul>
<p><strong>Model Explain Ability.</strong></p>
<p>Most businesses run on trust and being able to open the ML "black box" helps <strong>build transparency and trust</strong>. </p>
<p><strong>In heavily regulated industries like healthcare and banking, it is critical to comply with regulations and best practices.</strong></p>
<p>One key aspect of this is understanding the relationship between input variables (features) and model output. Knowing both the magnitude and direction of the impact each feature (feature importance) has on the predicted value helps better understand and explain the model. </p>
<p><strong>With model explain ability, we enable you to understand feature importance as part of automated ML runs.</strong></p>
<p>2) Which of the following are examples of data transformation modules available in Azure Machine Learning designer? (Choose 2 answers)</p>
<ul>
<li><strong>A. Split Data</strong></li>
<li><strong>B. Clean Missing Data</strong></li>
<li>C. Import Data</li>
<li>D. Dataset</li>
</ul>
<p>All of the options listed are examples of modules available in Azure Machine Learning designer. </p>
<p>However, only <strong>Split Data and Clean Missing Data are data transformation modules</strong>. </p>
<p>Data transformation modules are used to prepare data before a machine learning experiment. Common machine learning data preparation steps include <strong>cleaning missing data, normalizing data, or converting data from one file format to another</strong>.</p>
<p>3) A company employs a team of customer service agents to provide telephone and email support to customers.</p>
<p>The company develops a webchat bot to provide automated answers to common customer queries. <strong>Which business benefit should the company expect as a result of creating the webchat bot solution?</strong></p>
<ul>
<li>A. increased sales</li>
<li><strong>B. a reduced workload for the customer service agents</strong></li>
<li>C. Improved product reliability</li>
</ul>
<p>Correct Answer: B</p>
<p>Agent workload will be reduced by chatbot since it can answer simple questions</p>
<p>4) <strong>You are working on an application that supports an automation line in a factory.</strong> Several sensors provide data about equipment health, and you would like to use this data in real-time to identify potential line issues quickly. </p>
<p><strong>Which Azure cognitive service</strong> would be a good choice to help quickly <strong>identify issues based on your sensor data?</strong></p>
<ul>
<li><strong>A. Anomaly Detector</strong></li>
<li>B. Azure Monitor</li>
<li>C. Form Recognizer</li>
<li>D. Azure Auto Machine Learning</li>
</ul>
<p>Anomaly Detector is an Azure Cognitive service API that is used to <strong>identify anomalies in time-series data</strong>. </p>
<p>This service helps identify problems early and detect issues that might otherwise be too difficult see without automated analysis.</p>
<p>5) For a machine learning progress, how should you <strong>split data for training and evaluation</strong>?</p>
<ul>
<li>A. Use features for training and labels for evaluation.</li>
<li><strong>B. Randomly split the data into rows for training and rows for evaluation</strong>.</li>
<li>C. Use labels for training and features for evaluation.</li>
<li>D. Randomly split the data into columns for training and columns for evaluation.</li>
</ul>
<p><strong>Correct Answer: B</strong></p>
<p>The Split Data module is particularly useful when you need to separate data into training and testing sets.</p>
<p><strong>Use the Split Rows option if you want to divide the data into two parts. You can specify the percentage of data to put in each split, but by default, the data is divided 50-50.</strong> You can also randomize the selection of rows in each group, and use stratified sampling.</p>
<p>6) You are using Azure Machine Learning to develop a machine learning model to <strong>predict fuel efficiency (miles/gallon)</strong> for automobiles manufactured between 2000 and 2010. Which machine learning algorithm would be the best choice for building this model?</p>
<ul>
<li><strong>A. Regression</strong></li>
<li>B. Classification</li>
<li>C. Clustering</li>
<li>D. Reinforcement learning</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>In this scenario, you are predicting a single number: fuel efficiency. For problems that predict a continuous value, you would use a regression algorithm to build your model. </p>
<ul>
<li><strong>Classification algorithms are used to predict discrete values or classes</strong>, </li>
<li><strong>Clustering algorithms help uncover patterns and organize data into associated clusters.</strong></li>
</ul>
<p>7) You are developing a model to predict events by using classification.</p>
<p>You have a <strong>confusion matrix</strong> for the model scored on test data as shown in the following exhibit.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_1.png" title="Body image" /></p>
<p>Use the drop-down menus to select the answer choice that completes each statement based on the information presented in the graphic.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_2.png" title="Body image" /></p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_2_1.png" title="Body image" /></p>
<p>8) A customer support team would like to implement an <strong>interactive chat window</strong> on their product website that uses artificial intelligence (AI) to answer customer questions. </p>
<p>The team already has extensive frequently asked questions (FAQ) documentation available.</p>
<p>Which Azure AI solutions should this team use to build a chat program from their existing FAQ documentation?</p>
<ul>
<li><strong>A. QnA Maker + Azure Bot Service</strong></li>
<li>B. LUIS (Language Understanding) + Azure Functions</li>
<li>C. Text Analytics + Azure Bot Service</li>
<li>D. Form Recognizer + Azure Functions</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>In this case, the correct combination is to use Azure QnA Maker as the knowledge base to power a bot using Azure Bot Service and build a web chatbot. </p>
<p>It is also possible to use Language Understanding (LUIS) to power a bot instead of QnA Maker or in addition to QnA Maker. </p>
<p>However, since the organization will use the bot to answer questions from an existing frequently asked questions database, QA Maker is the correct choice.</p>
<p>9） For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_3.png" title="Body image" /></p>
<blockquote>
<p><strong>Regression</strong></p>
<p><strong>Anomly</strong></p>
<p><strong>Cassification</strong></p>
</blockquote>
<p>Anomaly detection encompasses many important tasks in machine learning:</p>
<ul>
<li>Identifying transactions that are potentially fraudulent.</li>
<li>Learning patterns that indicate that a network intrusion has occurred.</li>
<li>Finding abnormal clusters of patients.</li>
<li>Checking values entered into a system.</li>
</ul>
<p>10) To complete the sentence, select the appropriate option in the answer area.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_4.png" title="Body image" /></p>
<p><strong>Reliability and safety</strong>:</p>
<p>AI systems need to be reliable and safe in order to be trusted. It is important for a system to perform as it was originally designed and for it to respond safely to new situations. </p>
<p>Its inherent resilience should resist intended or unintended manipulation. Rigorous testing and validation should be established for operating conditions to ensure that the system responds safely to edge cases, and A/B testing and champion/challenger methods should be integrated into the evaluation process.</p>
<p>An AI system's performance can degrade over time, so a robust monitoring and model tracking process needs to be established to reactively and proactively measure the model's performance and retrain it, as necessary, to modernize it.</p>
<p>11) You are training an Azure Language Understanding (LUIS) model, and you plan to use with an interactive application that responds to user questions/commands. For example, a user may ask, "What is the temperature in Boston today?"</p>
<p>What is the term used to describe what the user might say to the application, in this case asking about the temperature in Boston?</p>
<ul>
<li><strong>A. utterance</strong></li>
<li>B. entity</li>
<li>C. intent</li>
<li>D. key phrase</li>
</ul>
<p><strong>The term utterance is used to describe the user's question or command that is the input sent to a LUIS endpoint for analysis.</strong></p>
<p>12) Match the types of AI workloads to the appropriate scenarios</p>
<p>To answer, drag the appropriate workload type from the column on the left to its scenario on the right. </p>
<p>Each workload type may be used once, more than once, or not at all.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p>Select and Place:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_5.png" title="Body image" /></p>
<p>13) You are designing an AI system that empowers everyone, <strong>including people who have hearing, visual, and other impairments</strong>.</p>
<p>This is an example of which Microsoft guiding principle for responsible AI?</p>
<ul>
<li>A. fairness</li>
<li><strong>B. inclusiveness</strong></li>
<li>C. reliability and safety</li>
<li>D. accountability</li>
</ul>
<p><strong>Correct Answer: B</strong></p>
<p>Inclusiveness: At Microsoft, we firmly believe everyone should benefit from intelligent technology, meaning it must incorporate and address a broad range of human needs and experiences. For the 1 billion people with disabilities around the world, AI technologies can be a game-changer.</p>
<p>14) You are working on an application that uses computer vision to <strong>identify unwanted plant species growing alongside crops in farmer's fields</strong>. Which Azure Cognitive Service is the best choice to help you train your image classification model?</p>
<ul>
<li><strong>A. Custom Vision</strong></li>
<li>B. Computer Vision</li>
<li>C. Anomaly Detector</li>
<li>D. Azure Machine Learning clustering analysis</li>
</ul>
<p>Correct Answer: A</p>
<p>Though Azure Computer Vision services can identify a wide range of features in images, it will not work well if you need to identify domain-specific features. </p>
<p>Instead, <strong>Azure Custom Vision services is a no-code option that you can use to train and deploy a custom image classification model.</strong></p>
<p>15) <strong>Match the Microsoft guiding principles for responsible AI to the appropriate descriptions.</strong> </p>
<p>To answer, drag the appropriate principle from the column on the left to its description on the right. Each principle may be used once, more than once, or not at all.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_6.png" title="Body image" /></p>
<p>Box 1: <strong>Reliability and safety</strong> - To build trust, it's critical that AI systems operate reliably, safely, and consistently under normal circumstances and in unexpected conditions. These systems should be able to operate as they were originally designed, respond safely to unanticipated conditions, and resist harmful manipulation.</p>
<p>Box 2: <strong>Accountability</strong> - The people who design and deploy AI systems must be accountable for how their systems operate. Organizations should draw upon industry standards to develop accountability norms. </p>
<p>These norms can ensure that AI systems are not the final authority on any decision that impacts people's lives and that humans maintain meaningful control over otherwise highly autonomous AI systems.</p>
<p>Box 3: <strong>Privacy and security</strong> - As AI becomes more prevalent, protecting privacy and securing important personal and business  information is becoming more critical and complex. </p>
<p>With AI, privacy and data security issues require especially close attention because access to data is essential for AI systems to make accurate and informed predictions and decisions about people. AI systems must comply with privacy laws that require transparency collection，use，and storage if data and mandate that  consumers have appropriate controls to choose how their data is used </p>
<p>17) You plan to integrate Azure QnA Maker with Azure Bot Services to build a conversational AI system to help answer user questions. What information do you need to configure a new Azure Bot to connect with your QnA knowledge base? (Choose 3 answers)</p>
<ul>
<li><strong>A. OnA authorization key</strong></li>
<li><strong>B. QnA endpoint hostname</strong></li>
<li><strong>C. QnA knowledge base ID</strong></li>
<li>D. QnA app service name</li>
</ul>
<p><strong>Correct Answer: ABC</strong></p>
<p>To configure a new Azure Bot and connect with your QnA knowledge base, you will need:</p>
<ol>
<li>QA authorization key</li>
<li>QnA endpoint hostname</li>
<li>QnA knowledge base ID</li>
</ol>
<p>18) You are building an AI system.</p>
<p>Which task should you include to ensure that the service meets the Microsoft transparency principle for responsible AI?</p>
<ul>
<li>A. Ensure that all visuals have an associated text that can be read by a screen reader.</li>
<li>B. Enable autoscaling to ensure that a service scales based on demand.</li>
<li><strong>C. Provide documentation to help developers debug code.</strong></li>
<li>D. Ensure that a training dataset is representative of the population.</li>
</ul>
<p><strong>Correct Answer: C</strong></p>
<p>Achieving transparency helps the team to understand the data and algorithms used to train the model, what transformation logic was applied to the data, the final model generated, and its associated assets. This information offers insights about how the model was created, which allows it to be reproduced in a transparent way. </p>
<p>Snapshots within Azure Machine Learning workspaces support transparency by recording or retraining all training-related assets and metrics involved in the experiment.</p>
<p><strong>19) You have been given a data set that is unlabeled and includes detailed customer information.</strong></p>
<p>You would like to use Azure Machine Learning to <strong>uncover data patterns and groupings</strong>. Which machine learning algorithm is the best choice?</p>
<ul>
<li><strong>A. Clustering</strong></li>
<li>B. Classification</li>
<li>C. Regression</li>
<li>D. Reinforcement Learning</li>
</ul>
<p>Correct Answer: A</p>
<p>This is an example of a clustering machine learning problem. </p>
<p>Clustering algorithms are an example of unsupervised machine learning. </p>
<p>You use clustering analysis to uncover patterns in your data and when you are working with unlabeled data. You would use clustering to answer a question like, "How is this data organized?"</p>
<p><strong>20) Match the types of AI workloads to the appropriate scenarios.</strong></p>
<p>To answer, drag the appropriate workload type from the column on the left to its scenario on the right. Each workload type may be used once, more than once, or not at all.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_7.png" title="Body image" /></p>
<ul>
<li>Computer vision = identify (object) letters</li>
<li><strong>NLP = sentiment</strong></li>
<li>Anomaly Detection = fraud</li>
<li><strong>Machine Learning (regression) = predict</strong></li>
</ul>
<p>21) You are writing an application that <strong>analyzes customer product reviews and flags reviews that have a negative sentiment.</strong> Which Azure Cognitive Service would you use to provide sentiment analysis and mark text as positive, negative, or neutral?</p>
<ul>
<li><strong>A. Text Analytics API</strong></li>
<li>B. Language Understanding (LUIS)</li>
<li>C. Speech Translation</li>
<li>D. Content Moderator</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>The Text Analytics API has the ability to take an input text document and return the predicted author's sentiment (positive, negative, or neutral).</p>
<p>22) Your company is exploring the use of voice recognition technologies in its smart home devices. The company wants to identify any barriers that might unintentionally leave out specific user groups.</p>
<p>This an example of which Microsoft guiding principle for responsible AI?</p>
<ul>
<li>A. accountability</li>
<li>B. fairness</li>
<li><strong>C. inclusiveness</strong></li>
<li>D. privacy and security</li>
</ul>
<p>Correct Answer: C</p>
<p>Inclusiveness mandates that AI should consider all human races and experiences, and inclusive design practices can help developers to understand and address potential barriers that could unintentionally exclude people. </p>
<p>Where possible, speech-to-text, text-to-speech, and visual recognition technology should be used to empower people with hearing, visual, and other impairments.</p>
<p>23) What are three Microsoft guiding principles for responsible AI? Each correct answer presents a complete solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li>A. knowledgeability</li>
<li>B. decisiveness</li>
<li><strong>C. inclusiveness</strong></li>
<li><strong>D. fairness</strong></li>
<li>E. opinionatedness</li>
<li><strong>F. reliability and safety</strong></li>
</ul>
<p><strong>Correct Answer: CDF</strong></p>
<p>24) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_8.png" title="Body image" /></p>
<p>Object detection is similar to tagging, but the API returns the bounding box coordinates (in pixels) for each object found in the image. </p>
<p>For example, if an image contains a dog, cat and person, the Detect operation will list those objects with their coordinates in the image. You can use this functionality to process the relationships between the objects in an image. </p>
<p>It also lets you determine whether there are multiple instances of the same object in an image.</p>
<p>25) Which of the following types of machine learning problems are supported with Azure Automated Machine Learning (AutoML)? (Choose 3 answers)</p>
<ul>
<li><strong>A. Regression</strong></li>
<li><strong>B. Classification</strong></li>
<li><strong>C. Time-series forecasting</strong></li>
<li>D. Conversational AI</li>
</ul>
<p>Correct Answer: ABC</p>
<p>Azure AutoML supports finding the best regression, classification, and time-series forecasting models. When you configure an AutoML experiment, you will need to specify which of these types of machine learning problems you are trying to solve.</p>
<p>26) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_9.png" title="Body image" /></p>
<p>Explaination - feature engineering is applied first to generate additional features, and then feature selection is done to eliminate irrelevant, redundant, or highly correlated features.</p>
<p>27) You run a charity event that involves posting photos of people wearing sunglasses on Twitter.</p>
<p>You need to ensure that you only retweet photos that meet the following requirements:</p>
<ul>
<li>Include one or more faces.</li>
<li>Contain at least one person wearing sunglasses.</li>
</ul>
<p>What should you use to analyze the images?</p>
<ul>
<li>A. the Verify operation in the Face service</li>
<li><strong>B. the Detect operation in the Face service</strong></li>
<li>C. the Describe Image operation in the Computer Vision service</li>
<li>D. the Analyze Image operation in the Computer Vision service</li>
</ul>
<p><strong>Correct Answer: B</strong></p>
<blockquote>
<p><strong>Face detect can be requested to detect also glasses attribute</strong></p>
</blockquote>
<p>Face detection is required as a first step in all the other scenarios. The Detect API detects human faces in an image and returns the rectangle coordinates of their locations. It also returns a unique ID that represents the stored face data. </p>
<p>This is used in later operations to identify or verify faces. Optionally, face detection can extract a set of face-related attributes, such as head pose, age,emotion, facial hair, and glasses. </p>
<p>These attributes are general predictions, not actual classifications. Some attributes are useful to
ensure that your application is getting high-quality face data when users add themselves to a Face service. For example, yourapplication could advise users to take off their sunglasses if they're wearing sunglasses.</p>
<p>28) Which of the following statements are true about the data used to train and evaluate machine learning model？</p>
<ul>
<li><strong>A. You should split the data set into two datasets; one dataset is used to train the model, and the other dataset to evaluate the model.</strong></li>
<li>B. You should always use the same data to evaluate the model that you used to train it.</li>
<li>C. The only time you need to split a dataset into training and test sets is when using a regression algorithm.</li>
<li>D. When splitting a dataset into training and test datasets, the data should remain <strong><em>in order</em></strong> with the first 70-80% of the data included in the training dataset, and the remaining rows in the test dataset.</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>When training and evaluating a new machine learning model, it is important to split the dataset into a training and test data set. The training dataset is used to train the model, and the test dataset is used to evaluate the model. </p>
<p>When splitting the data, the rows in the dataset should be selected randomly for the split operation. As a rule of thumb, 70-80%
of the data goes to the training dataset, with the remaining data added to the test dataset.</p>
<p>29)  When you design an AI system to assess whether loans should be approved, <strong>the factors used to make the decision should be explainable.</strong></p>
<p>This is an example of which Microsoft guiding principle for responsible AI?</p>
<ul>
<li><strong>A. transparency</strong></li>
<li>B. inclusiveness</li>
<li>C. fairness</li>
<li>D. privacy and security</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>Achieving transparency helps the team to understand the data and algorithms used to train the model, what transformation logic
was applied to the data, the final model generated, and its associated assets. This information offers insights about how the
model was created, which allows it to be reproduced in a transparent way.</p>
<p>Incorrect Answers:</p>
<p>B: Inclusiveness mandates that AI should consider all human races and experiences, and inclusive design practices can help developers to understand and address potential barriers that could unintentionally exclude people. </p>
<p>Where possible, speech-to-text, text-to-speech, and visual recognition technology should be used to empower people with hearing, visual, and other impairments.</p>
<p>C: Fairness is a core ethical principle that all humans aim to understand and apply. This principle is even more important when AI systems are being developed.</p>
<p>Key checks and balances need to make sure that the system's decisions don't discriminate or run a gender, race, sexualorientation, or religion bias toward a group or individual.</p>
<p>D: A data holder is obligated to protect the data in an AI system, and privacy and security are an integral part of this system.</p>
<p>Personal needs to be secured, and it should be accessed in a way that doesn't compromise an individual's privacy.</p>
<p>30) For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_10.png" title="Body image" /></p>
<ul>
<li>1 Yes</li>
<li><strong>2 No it should be related to "privacy and security"</strong></li>
<li><strong>3 No it should be related to "fairness"</strong></li>
</ul>
<p><strong>Box 1: Yes -</strong></p>
<p>Achieving transparency helps the team to understand the data and algorithms used to train the model, what transformation logic
was applied to the data, the final model generated, and its associated assets. This information offers insights about how the
model was created, which allows it to be reproduced in a transparent way.</p>
<p><strong>Box 2: No -</strong></p>
<p>A data holder is obligated to protect the data in an AI system, and privacy and security are an integral part of this system.</p>
<p>Personal needs to be secured, and it should be accessed in a way that doesn't compromise an individual's privacy.</p>
<p><strong>Box 3: No -</strong></p>
<p>Inclusiveness mandates that AI should consider all human races and experiences, and inclusive design practices can help developers to understand and address potential barriers that could unintentionally exclude people. Where possible, speech-to-text, text-to-speech, and visual recognition technology should be used to empower people with hearing, visual, and other impairments.</p>
<p>31) Which of the following <strong>Azure Cognitive Services can be integrated with Azure Bot Services</strong> as the engine that recognizes user intent to create an interactive chatbot application?</p>
<ul>
<li><strong>A Language Understanding (LUIS)</strong></li>
<li>B. Custom Vision</li>
<li>C. Anomaly Detector</li>
<li>D. Text Analytics</li>
</ul>
<p>When you create a bot using Azure Bot Services, you need an Azure Cognitive Service with natural language processing to understand and respond to user input. </p>
<p>A simple solution would be to use QnA Maker that could be based on an existing frequently asked question knowledge base. </p>
<p>However, if the user interaction goes beyond a simple question and answer conversation and should include understanding and processing commands, QA Maker would not be the right choice. Instead, <strong>the Language Understanding service (LUIS)</strong> would be the best option to
integrate with the chatbot. A LUIS service can extract intent (what the user wants) and entities (the objects associated with the request/action)</p>
<p>32) Match the principles of responsible AI to appropriate requirements.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_11.png" title="Body image" /></p>
<p>33) You are creating a bot using Azure Bot Service with QnA Maker as its knowledge base. Which of the statements regarding bot communication channels are correct? (Choose 2 answers)</p>
<ul>
<li><strong>A. A web chat channel is automatically created for you when you create a bot</strong>.</li>
<li><strong>B. It is possible to send messages to and receive messages from a bot service using Microsoft Teams.</strong></li>
<li>C. Communicating with a bot service through an email channel is not supported.</li>
<li>D. A bot service can be associated with only one communication channel</li>
</ul>
<p>Correct Answer: AB</p>
<p>When you create a bot using Azure Bot Service, a webchat channel is automatically created for you. There are also many other channels that you can associate with your bot, including an email channel and a Microsoft Teams channel. A bot service can be associated with one or more communication channels.</p>
<p>34) You plan to deploy an <strong>Azure Machine Learning model as a service that will be used by client applications</strong>.</p>
<p>Which three processes should you perform in sequence before you deploy the model? To answer, move the appropriate processes from the list of processes to the answer area and arrange them in the correct order.</p>
<p>Select and Place:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_12.png" title="Body image" /></p>
<ol>
<li>data preparation</li>
<li>model training</li>
<li>model evaluation</li>
</ol>
<p>35) <strong>You are building an AI-based app</strong>.</p>
<p>You need to ensure that the app uses the principles for responsible AI.</p>
<p>Which two principles should you follow? Each correct answer presents part of the solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li>A. Implement an Agile software development methodology</li>
<li><strong>B. Implement a process of AI model validation as part of the software review process</strong></li>
<li><strong>C. Establish a risk governance committee that includes members of the legal team, members of the risk management team, and a privacy officer</strong></li>
<li>D. Prevent the disclosure of the use of AI-based algorithms for automated decision-making</li>
</ul>
<p>Correct Answer: BC</p>
<p><strong>B ensures reliability and safety principle and C ensures privacy and security principle of AI.</strong></p>
<p>36） When setting up an Azure AutoML experiment, which of the following configuration values are specified for the experiment? Select two answers.</p>
<ul>
<li>A. A <strong>primary metric</strong> used to compare the results of individual experimental runs.</li>
<li>B. A list of <strong>blocked algorithms</strong> that should be excluded from the training runs.</li>
<li>C. The <strong>hostname</strong> where the best model from the experimental runs should be deployed.</li>
<li>D. The <strong>maximum time</strong> allowed to run all experimental runs.</li>
</ul>
<p>Correct Answer: AB</p>
<p>When setting up an AutoML experiment, the <strong>primary metric</strong> is the evaluation metric by which each AutoML run is compared. </p>
<p>The primary metric you choose will depend on the type of machine learning algorithm you are using; </p>
<p>Regression algorithms use different primary metrics than classification algorithms. </p>
<p>Also available for configuration while setting up an AutoML run is the list of blocked algorithms. With this list, you can explicitly specify a set of algorithms that AutoML will skip while running experiments to determine the best algorithm. For a complete list of configuration settings, see the AutoML product documentation.</p>
<p>37) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_13.png" title="Body image" /></p>
<ul>
<li>Inclusiveness = accessible to all</li>
<li>Fairness = treat all without prejudice or bias</li>
</ul>
<p>38) Match the types of AI workloads to the appropriate scenarios.</p>
<p>To answer, drag the appropriate workload type from the column on the left to its scenario on the right. Each workload type may be used once, more than once, or not at all.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_14.png" title="Body image" /></p>
<p>Box 1: Knowledge mining -</p>
<p>You can use Azure Cognitive Search's knowledge mining results and populate the knowledge base of your chatbot.</p>
<p>Box 2: Computer vision -</p>
<p>Box 3: Natural language processing</p>
<p>Natural language processing (NLP) is used for tasks such as sentiment analysis.</p>
<p>39) You are using Azure's Computer Vision service to suggest tags that describe features identified in an image. <strong>You are using the computer vision REST endpoint, and the JSON response includes one or more tags that have been identified.</strong></p>
<p>What other information is also included with each tag in the JSON response?</p>
<ul>
<li><strong>A. A confidence score that indicates how likely the tag correctly matches the content in the image.</strong></li>
<li>B. A set of coordinates is given by a bounding box that identifies the tag's location in the image.</li>
<li>C. A URL that provides a full description of the tag.</li>
<li>D. A count indicating how many times the tag is found in the image.</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>Each tag in the response includes the name of the tag and a confidence score that indicates how likely the tag correctly matches the content in the image.</p>
<p>A confidence score is a number from 0 to 1, with values closer to 1 indicating high confidence that the tag correctly identifies features in the image. </p>
<p>Tags do not include a bounding box to locate each feature. If location information is needed, use the object detection computer vision API instead.</p>
<p>40) Match the machine learning tasks to the appropriate scenarios.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_15.png" title="Body image" /></p>
<ul>
<li><strong>Feature engineering = splitting</strong></li>
<li><strong>Feature selection = picking</strong></li>
</ul>
<p>41) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_16.png" title="Body image" /></p>
<p>42) You would like to have your web chatbot application support speech output. Which of the following channels would you need to configure for your bot service?</p>
<ul>
<li><strong>A. Direct Line channel</strong></li>
<li>B. Custom channel</li>
<li>C. Voice channel</li>
<li>D. Speech channel</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>You will need a direct line channel to support speech output for your web chatbot application.</p>
<p>43) You have the Predicted vs. True chart shown in the following exhibit.</p>
<p>Which type of model is the chart used to evaluate?</p>
<ul>
<li>A. classification</li>
<li><strong>B. regression</strong></li>
<li>C. clustering</li>
</ul>
<p><strong>Correct Answer: B</strong></p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_17.png" title="Body image" /></p>
<p>What is a Predicted vs. True chart?</p>
<p>Predicted vs. True shows the relationship between a predicted value and its correlating true value for a regression problem. This graph can be used to measure the performance of a model as the closer to the y=x line the predicted values are, the better the accuracy of a predictive model.</p>
<p>44) Which type of machine learning should you use to predict the number of gift cards that will be sold next month?</p>
<ul>
<li>A. classification</li>
<li><strong>B. regression</strong></li>
<li>C. clustering</li>
</ul>
<p><strong>Correct Answer: B</strong></p>
<p>In the most basic sense, regression refers to prediction of a numeric target.</p>
<p>Linear regression attempts to establish a linear relationship between one or more independent variables and anumeric outcome, or dependent variable.</p>
<p>You use this module to define a linear regression method, and then train a model using a labeled dataset. The trained model can then be used to make predictions</p>
<p>45) Which of the following statements best describes the characteristics of a classification model in Azure Machine Learning? (Choose 2 answers)</p>
<ul>
<li><strong>A. Classification algorithms use labeled training data to build a model and predict the category  (class) of yet unseen data items.</strong></li>
<li>B. Classification algorithms are an example of unsupervised machine learning.</li>
<li>C. Classification algorithms take unlabeled data and groups the data into two or more categories (classes).</li>
<li><strong>D. Classification algorithms can predict both binary and multi-class classification problems</strong>.</li>
</ul>
<p>Classification algorithms use labeled training data to build a model and predict the category (class) of unseen data items. </p>
<p>Classification algorithms are an example of supervised learning and can predict either binary or multi-class classification problems.</p>
<p>It is clustering algorithms, and not classification algorithms take unlabeled data and group the data into two or more categories (classes).</p>
<p>46) You have a dataset that contains information about taxi journeys that occurred during a given period.</p>
<p><strong>You need to train a model to predict the fare of a taxi journey.</strong></p>
<p>What should you use as a feature?</p>
<ul>
<li>A. the number of taxi journeys in the dataset</li>
<li><strong>B. the trip distance of individual taxi journeys</strong></li>
<li>C. the fare of individual taxi journeys</li>
<li>D. the trip ID of individual taxi journeys</li>
</ul>
<p>Correct Answer: B</p>
<p>The label is the column you want to predict. The identified Features are the inputs you give the model to predict the Label.</p>
<p>Example:</p>
<p>The provided data set contains the following columns:</p>
<ul>
<li><code>vendor_id</code>: The ID of the taxi vendor is a feature.</li>
<li><code>rate_code</code>: The rate type of the taxi trip is a feature.</li>
<li><code>passenger_count</code>: The number of passengers on the trip is a feature. </li>
<li><code>trip_time_in_secs:</code> The amount of time the trip took.</li>
</ul>
<p><strong>You want to predict the fare of the trip before the trip is completed.</strong> </p>
<p>At that moment, you don't know how long the trip would take. <strong>Thus, the trip time is not a feature and you'll exclude this column from the model</strong>. </p>
<ul>
<li>
<p><code>trip_distance</code>: The distance of the trip is a feature. payment_type: The payment method (cash or credit card) is a feature. </p>
</li>
<li>
<p><code>fare_amount</code>: The total taxi fare paid is the label.</p>
</li>
</ul>
<p>47) You need to predict the sea level in meters for the next 10 years. Which type of machine learning should you use?</p>
<ul>
<li>A. classification</li>
<li><strong>B. regression</strong></li>
<li>C. clustering</li>
</ul>
<p>Correct Answer: B</p>
<p>In the most basic sense, regression refers to prediction of a numeric target.</p>
<p>Linear regression attempts to establish a linear relationship between one or more independent variables and a numeric outcome, or dependent variable.</p>
<p>You use this module to define a linear linear regression method, and then train a model using a labeled dataset. </p>
<p>The trained model can then be used to make predictions.</p>
<p>48) What key piece of information do you need to call your QnA Maker service from a client application?</p>
<ul>
<li><strong>A. The REST endpoint URL for your QnA Maker service</strong></li>
<li>B. The globally unique QnA Maker application name</li>
<li>C. The hostname for the machine hosting your QnA Maker service</li>
<li>D. The region where your QnA Maker service is deployed</li>
</ul>
<p>Correct Answer: A</p>
<p>After setting up and training QnA Maker, you will need the REST endpoint URL for your QnA Maker service.</p>
<p>49) For each of the following statements, select Yes if the statement is true. Otherwise, select No.
NOTE: Each correct selection is worth one point.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_18.png" title="Body image" /></p>
<p><strong>Box 1: Yes</strong></p>
<p>Automated machine learning, also referred to as automated ML or AutoML, <strong>is the process of automating the time-consuming, iterative tasks of machine learning model development</strong>. It allows data scientists, analysts, and developers to build ML models with high scale, efficiency, and productivity all while sustaining model quality.</p>
<p>Box 3: Yes - During training, Azure Machine Learning creates a number of pipelines in parallel that try different algorithms and parameters for you. </p>
<p>The service iterates through ML algorithms paired with feature selections, where each iteration produces a model with a training score. The higher the score, the better the model is considered to "fit" your data. It will stop once it hits the exit criteria defined in the experiment.</p>
<p>Box 4: No - Apply automated ML when you want Azure Machine Learning to train and tune a model for you using the target metric you specify.</p>
<p>The label is the column you want to predict.</p>
<p>50)  To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_19.png" title="Body image" /></p>
<p>Two-class classification provides the answer to simple two-choice questions such as Yes/No or
True/False.</p>
<p>51） ___ occurs when a model matches training data so closely that it doesn't generalize well to other data.</p>
<ul>
<li>A. Underfitting</li>
<li><strong>B. Overfitting</strong></li>
<li>C. Drift</li>
<li>D. Root mean squared error</li>
</ul>
<p><strong>Correct Answer: B</strong></p>
<p>A common problem to be on the lookout for with any machine learning model is <strong>overfitting the data</strong>. </p>
<p>Overfitting happens when the model performs very well on the training dataset but does not perform well with unseen test data.</p>
<p>52)  For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_20.png" title="Body image" /></p>
<p><strong>Box 1: Yes -</strong></p>
<p>In machine learning, if you have labeled data, that means your data is marked up, or annotated, to show the target, which is the answer you want your machine learning model to predict.</p>
<p><strong>In general, data labeling can refer to tasks that include data tagging, annotation, classification, moderation, transcription, or processing.</strong></p>
<p><strong>Box 3: No -</strong></p>
<p>Accuracy is simply the proportion of correctly classified instances. It is usually the first metric you look at when evaluating a classifier. However, when the test data is unbalanced (where most of the instances belong to one of the classes), or you are more interested in the performance on either one of the classes, accuracy doesn't really capture the effectiveness of a classifier.</p>
<p>53) Which service should you use to extract text, key/value pairs, and table data automatically from scanned documents?</p>
<ul>
<li><strong>A. Form Recognizer</strong></li>
<li>B. Text Analytics</li>
<li>C. Language Understanding</li>
<li>D. Custom Vision</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>Accelerate your business processes by automating information extraction. Form Recognizer applies advanced machine learning to accurately extract text, key/ value pairs, and tables from documents. With just a few samples, Form Recognizer tailors its understanding to your documents, both on-premises and in the cloud. </p>
<p>Turn forms into usable data at a fraction of the time and cost, so you can focus more time acting on the information rather than compiling it.</p>
<p>54) Azure Speech Services can be used in a variety of applications. Which of the following correctly matches the use case with the appropriate speech service? (Choose 2 answers)</p>
<p>A. <strong>Use case</strong>: Create closed captions for a recorded video</p>
<p><strong>Service</strong>: Speech-to-Text</p>
<p>B. <strong>Use case</strong>: Read a text message aloud</p>
<p>Service: Text-to-Speech</p>
<p>C. <strong>Use case</strong>: Dictate a note or text message
Service: Speech Translation</p>
<p>D. <strong>Use case</strong>: Identify user sentiment in a recorded voice message</p>
<p>Service: Speech-to-Text</p>
<p>Correct Answer: AB</p>
<p>55) Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_21.png" title="Body image" /></p>
<p>Accelerate your business processes by automating information extraction. </p>
<p>Form Recognizer applies advanced machine learning to accurately extract text, key/ value pairs, and tables from documents. With just a few samples, Form Recognizer tailors its understanding to your documents, both on-premises and in the cloud. </p>
<p>Turn forms into usable data at a fraction of the time and cost, so you can focus more time acting on the information rather than compiling it.</p>
<p>56) You use Azure Machine Learning designer to publish an inference pipeline.</p>
<p>Which two parameters should you use to access the web service? Each correct answer presents part of the solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li>A. the model name</li>
<li>B. the training endpoint</li>
<li><strong>C. the authentication key</strong></li>
<li><strong>D. the REST endpoint</strong></li>
</ul>
<p>Correct Answer: CD</p>
<p>You can consume a published pipeline in the Published pipelines page. Select a published pipeline and find the REST endpoint of it.</p>
<p>To consume the pipeline, vou need:</p>
<ul>
<li>The REST endpoint for your service</li>
<li>The Primary Key for vour service</li>
</ul>
<p>57) Which of the following features are supported by the <strong>Azure Text Analytics API</strong>? (Choose 2 answers)</p>
<ul>
<li><strong>A. language detection</strong></li>
<li><strong>B. named entity recognition</strong></li>
<li>C. text to speech services</li>
<li>D. text identification in an image</li>
</ul>
<p><strong>Correct Answer: AB</strong></p>
<p>The Azure Text Analytics API supports language detection and named entity recognition, along with several other features. </p>
<p>Language detection is used to detect the language for a given text document. Named entity recognition can identify people, places, organizations, and quantities included in an input text document.</p>
<p>The other features that are listed in the choice list are available with other Azure Cognitive Services:</p>
<ul>
<li><strong>Feature</strong>: user intent extraction, <strong>Service</strong>: Language Understanding (LUIS)</li>
<li><strong>Feature</strong>: text to speech services, <strong>Service</strong>: Text-to-Speech service</li>
<li><strong>Feature</strong>: text identification in an image, <strong>Service</strong>: Computer Vision - Optical Character Recognition (OCR)</li>
</ul>
<p>58) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_22.png" title="Body image" /></p>
<p>To perform real-time inferencing, you must deploy a pipeline as a real-time endpoint.</p>
<p>Real-time endpoints must be deployed to an Azure Kubernetes Service cluster.</p>
<p>59) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_23.png" title="Body image" /></p>
<p>In the most basic sense, regression refers to the prediction of a numeric target.</p>
<p>Linear regression attempts to establish a linear relationship between one or more independent variables and a numeric outcome, or dependent variable.</p>
<p>You use this module to define a linear regression method, and then train a model using a labeled dataset. The trained model can then be used to make predictions.</p>
<p>60) You have just trained and published an Azure Language Understanding (LUIS) model. </p>
<p>You plan to use the REST endpoint in your application to respond to user questions and commands. When you send a user question or command to the REST endpoint for your LUIS model, what information is included in the response? (Choose 2 answers)</p>
<ul>
<li><strong>A. A list of intents with a confidence score.</strong></li>
<li>B. A list of potential utterances with a confidence score.</li>
<li><strong>C. A list of entities extracted from the input question/command</strong>.</li>
<li>D. The lanquage of the input question/command.</li>
</ul>
<p>The primary information included in a response from invoking a LUIS endpoint with a command or question as input is:</p>
<ol>
<li>The top intent (best confidence score)</li>
<li>A list of all intents (and associated confidence score)</li>
<li>A list of entities extracted from the input question/command (utterance)</li>
</ol>
<p>The confidence score assigned to each intent is a value from 0 to 1, with values closer to 1 indicating greater confidence that the intent has been correctly identified.</p>
<p>For more information about the JSON response from invoking a LUIS endpoint, see the LUIS Documentation.</p>
<p>61) For each of the following statements, select Yes if the statement is true. Otherwise, select No</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_24.png" title="Body image" /></p>
<p>Box 1: Yes</p>
<p>Azure Machine Learning designer lets you visually connect datasets and modules on an interactive canvas to create machine-learning models.</p>
<p>Box 2: Yes -</p>
<p>With the designer you can connect the modules to create a pipeline draft.
As you edit a pipeline in the designer, your progress is saved as a pipeline draft.</p>
<p>Box 3: No - <strong>You can customize but only using Python and R code</strong></p>
<p>62) You have the following dataset.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_25.png" title="Body image" /></p>
<p>You plan to use the dataset to train a model that will predict the house price categories of houses.</p>
<p>What are Household Income and House Price Categories? To answer, select the appropriate option in the answer area.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_26.png" title="Body image" /></p>
<p>63) To complete the sentence, <strong>select the appropriate option</strong> in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_27.png" title="Body image" /></p>
<p>64) <strong>You are working on an application that uses Azure Machine Learning to predict the correct medication and dosage for a patient based on their symptoms</strong>. </p>
<p>The application must undergo rigorous testing and validation before product launch to ensure patients are given the proper medication. Which responsible AI practice is addressed with proper testing and validation?</p>
<ul>
<li><strong>A. Reliability and safety</strong></li>
<li>B. Continuous improvement</li>
<li>C. Accountability</li>
<li>D. Inclusiveness</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>Properly testing and validating an AI product will ensure that it performs reliably and safely.</p>
<p>65) For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_28.png" title="Body image" /></p>
<p>66） A medical research project uses a large anonymized dataset of brain scan images that are categorized into predefined brain hemorrhage types.</p>
<p>You need to use machine learning to <strong>support early detection of the different brain hemorrhage types in the images</strong> before the images are reviewed by a person.</p>
<p>This is an example of which type of machine learning?</p>
<ul>
<li>A. clustering</li>
<li>B. regression</li>
<li><strong>C. classification</strong></li>
</ul>
<p><strong>Correct Answer: C</strong></p>
<p>67) Which Azure Machine Learning feature offers the ability to build and deploy no-code predictive models using a drag-and-drop interface?</p>
<ul>
<li><strong>A. Azure Machine Learning designer</strong></li>
<li>B. Azure Automated ML</li>
<li>C. Text Analytics</li>
<li>D. QnA Maker</li>
</ul>
<p>Correct Answer: A</p>
<p>Azure Machine Learning designer offers the ability to build and deploy no-code predictive models using a drag-and
drop interface.</p>
<p>68) When training a model, why should you randomly split the rows into separate subsets?</p>
<ul>
<li>A. to train the model twice to attain better accuracy</li>
<li>B. to train multiple models simultaneously to attain better performance</li>
<li><strong>C. to test the model by using data that was not used to train the model</strong></li>
</ul>
<p><strong>Correct Answer: C</strong></p>
<p>69) You need to predict the income range of a given customer by using the following dataset.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_29.png" title="Body image" /></p>
<p>Which two fields should you use as features? Each correct answer presents a complete solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li><strong>A. Education Level</strong></li>
<li>B. Last Name</li>
<li><strong>C. Age</strong></li>
<li>D. Income Range</li>
<li>E. First Name</li>
</ul>
<p><strong>Correct Answer: AC</strong></p>
<p><strong>First Name, Last Name, Age and Education Level are features. Income range is a label (what you want to predict).</strong> First
Name and Last Name are irrelevant in that they have no bearing on income. Age and Education level are the features you
should use.</p>
<p>70） Which of the following application features uses Natural Language Processing (NLP)? (Choose 2 answers)</p>
<ul>
<li><strong>A. Analyze written text and highlight key phrases.</strong></li>
<li><strong>B. Translate text from one language to another</strong>.</li>
<li>C. Translate a handwritten note contained in an image into text.</li>
<li>D. Locate text that is included in an image</li>
</ul>
<p><strong>Correct Answer: AB</strong></p>
<p>The following features use natural language processing (NLP):</p>
<ul>
<li>Translate text from one language to another.</li>
<li>Analyze written text and highlight key phrases.</li>
</ul>
<p>The other two features do not involve NLP. Instead, these features use optical character recognition (OCR) and involve identifying text within an image.</p>
<p>71) You are building a tool that will process images from retail stores and <strong>identify the products of competitors</strong>.</p>
<p>The solution will use a custom model.</p>
<p>Which Azure Cognitive Services service should you use?</p>
<ul>
<li><strong>A. Custom Vision</strong></li>
<li>B. Form Recognizer</li>
<li>C. Face</li>
<li>D. Computer Vision</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>Azure Custom Vision is an image recognition service that lets you build, deploy, and improve your own image identifier models. </p>
<p>An image identifie applies labels (which represent classifications or objects) to images, according to their detected visual characteristics. Unlike the Computer Vision service, Custom Vision allows you to specify your own labels and train custom models to detect them</p>
<p>72) For each of the following statements, select Yes if the statement is true. </p>
<p>Otherwise, select No.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_30.png" title="Body image" /></p>
<ul>
<li>Clustering is a machine learning task that is used to group instances of data into clusters that contain similar
characteristics. </li>
</ul>
<p>Clustering can also be used to identify relationships in a dataset </p>
<p>Regression is a machine learning task that is used to predict the value of the label from a set of related features.</p>
<p>73) Which statement about Azure Automated Machine Learning (AutoML) is true? (Choose 2 answers)</p>
<ul>
<li><strong>A. AutoML is used to automatically select the best machine learning algorithm for your dataset.</strong></li>
<li><strong>B. You can choose to use either the Python SDK or a no-code user interface to build an AutoML experiment</strong>.</li>
<li>C. In order to use AutoML, developers must have a strong understanding of various machine learning algorithms.</li>
<li>D. An AutoML will not perform a train-test split operation; you must provide both a train and test dataset for an AutoML experiment. </li>
</ul>
<p><strong>Correct Answer: AB</strong></p>
<p>Azure AutoML provides a no-code option to select the best machine learning algorithm for your dataset automatically. </p>
<p>To use AutoML, users do not need to have a strong background in machine learning. AutoML will automatically split your data into the appropriate train and test datasets needed to run and evaluate each experiment.</p>
<p>74) For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_31.png" title="Body image" /></p>
<p>Box 1: No-</p>
<p>The validation dataset is different from the test dataset that is held back from the training of the model.</p>
<p>Box 2: Yes -</p>
<p>A validation dataset is a sample of data that is used to give an estimate of model skill while tuning model's hyperparameters.</p>
<p>Box 3: No -</p>
<p>The Test Dataset, not the validation set, used for this. The Test Dataset is a sample of data used to provide an unbiased evaluation of a final model fit on the training dataset.</p>
<p>75) What are two metrics that you can use to <strong>evaluate a regression model</strong>? Each correct answer presents a complete solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li><strong>A. coefficient of determination (R2)</strong></li>
<li>B. F1 score</li>
<li><strong>C. root mean squared error (RMSE)</strong></li>
<li>D. area under curve (AUC)</li>
<li>E. balanced accuracy</li>
</ul>
<p>Correct Answer: AC</p>
<p><strong>A: R-squared (R2), or Coefficient of determination represents the predictive power of the model as a value between -inf and 1.00. 1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</strong></p>
<p><strong>C: RMS-loss or Root Mean Squared Error (RMSE) (also called Root Mean Square Deviation, RMSD), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</strong></p>
<p>Incorrect Answers:</p>
<p>B: F1 score also known as balanced F-score or <strong>F-measure is used to evaluate a classification model.</strong></p>
<p>D: <strong>aucROC or area under the curve (AUC) is used to evaluate a classification model</strong>.</p>
<p>78) You need to use Azure Machine Learning designer to build a model that will predict automobile prices.</p>
<p>Which type of modules should you use to complete the model? To answer, drag the appropriate modules to the correct
locations. </p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_32.png" title="Body image" /></p>
<p><strong>Box 1: Select Columns in Dataset</strong></p>
<p>For Columns to be cleaned, choose the columns that contain the missing values you want to change. You can choose multiple columns, but you
must use the same replacement method in all selected columns.</p>
<p><strong>Box 2: Split data -</strong></p>
<p>Splitting data is a common task in machine learning. You will split your data into two separate datasets. One dataset will train the model and
the other will test how well the model performed.</p>
<p><strong>Box 3: Linear regression</strong></p>
<p>Because you want to predict price, which is a number, you can use a regression algorithm. For this example, you use a linear regression model.</p>
<p>79) Which type of machine learning should you use to identify groups of people who have similar purchasing habits?</p>
<ul>
<li>A. classification</li>
<li>B. regression</li>
<li><strong>C. clustering</strong></li>
</ul>
<p><strong>Correct Answer: C</strong></p>
<p>Whenever the questions involves groups, it's about clustering</p>
<p>Clustering is a machine learning task that is used to group instances of data into clusters that contain similar characteristics. </p>
<p>Clustering can also be used to identify relationships in a dataset</p>
<p>80) When using Azure Cognitive Services, which of the following is not a common computer vision task?</p>
<ul>
<li><strong>A. Translate text found in an image from one language to another.</strong></li>
<li>B. Detect human faces within an image.</li>
<li>C. Detect handwritten text within an image.</li>
<li>D. Classify an image based on what the image contains.</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>While it is possible to detect text in an image, translating the text from one language to another is not a computer vision
task. </p>
<p>It is possible to translate text from one language to another using the Translator service.</p>
<p>81) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_33.png" title="Body image" /></p>
<p>Regression is a machine learning task that is used to predict the value of the label from a set of related features.</p>
<p>82) Which metric can you use to evaluate a classification model?</p>
<ul>
<li><strong>A. true positive rate</strong></li>
<li>B. mean absolute error (MAE)</li>
<li>C. coefficient of determination (R2)</li>
<li>D. root mean squared error (RMSE)</li>
</ul>
<p><strong>MAE, RMSE and R2 are metris for regression:</strong></p>
<p>Correct Answer: A</p>
<p>What does a good model look like?</p>
<p><strong>An ROC curve that approaches the top left corner with 100% true positive rate and 0% false positive rate will be the best model.</strong> </p>
<p>A random model would display as a flat line from the bottom left to the top right corner. Worse than random would dip below the y=x line.</p>
<p>83) You work for an analytics company and are working on an application to detect credit card fraud. You want to create a model to predict whether or not a particular credit card transaction is fraudulent.</p>
<p>You have historical transaction data to build your model. Which Azure Service should you use to build this model?</p>
<ul>
<li><strong>A. Azure Machine Learning</strong></li>
<li>B. Anomaly Detection</li>
<li>C. Text Analytics</li>
<li>D. Form Recognizer</li>
</ul>
<p>Correct Answer: A</p>
<p>The following services are part of the Azure Cognitive Services:</p>
<ul>
<li>Form Recognizer</li>
<li>Text Analytics</li>
<li>Anomaly Detection</li>
</ul>
<p>Cognitive Services allow developers to build AI-based applications without significant AI, machine learning, or Data Sciences skills. In a way, you can consider Cognitive Services are MLaaS, Machine Learning as a Service. </p>
<p>This type of pre-built service is not what is needed in the scenario presented. Instead, you have been asked to build a custom prediction model based on your particular dataset. For this, you would use Azure Machine Learning. </p>
<p>There are no-code options available to help build models, even if you do not have significant machine learning knowledge.</p>
<p>84) Which two components can you drag onto a canvas in Azure Machine Learning designer? Each correct answer presents a complete solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li><strong>A. dataset</strong></li>
<li>B. compute</li>
<li>C. pipeline</li>
<li><strong>D. module</strong></li>
</ul>
<p><strong>Correct Answer: AD</strong></p>
<p>You can drag-and-drop datasets and modules onto the canvas.</p>
<p>85) You need to create a training dataset and validation dataset from an existing dataset.</p>
<p>Which module in the Azure Machine Learning designer should you use?</p>
<ul>
<li>A. Select Columns in Dataset</li>
<li>B. Add Rows</li>
<li><strong>C. Split Data</strong></li>
<li>D. Join Data</li>
</ul>
<p>Correct Answer: C</p>
<p>A common way of evaluating a model is to divide the data into a training and test set by using Split Data, and then validate the model on the training data.</p>
<p>Use the Split Data module to divide a dataset into two distinct sets.</p>
<p>The studio currently supports training/validation data splits</p>
<p>86) Which of the following Azure Cognitive Services would you choose to help build a conversational client application using artificial intelligence to answer customer questions?</p>
<ul>
<li><strong>A. QnA Maker</strong></li>
<li>B. Text Analytics</li>
<li>C. Form Recognizer</li>
<li>D. Content Moderator</li>
</ul>
<p>Correct Answer: A</p>
<p>If you are would like to build a bot that pulls information from existing FAQ documents to answer user questions, then QnA Make is the right choice to build your bot's knowledge base.</p>
<p>87) Match the types of machine learning to the appropriate scenarios.</p>
<p>Select and Place:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_34.png" title="Body image" /></p>
<p><strong>Box 1: Regression - In the most basic sense, regression refers to prediction of a numeric target.</strong></p>
<p>Linear regression attempts to establish a linear relationship between one or more independent variables and a numeric outcome, or dependent variable.</p>
<p>You use this module to define a linear regression method, and then train a model using a labeled dataset. The trained model can then be used to make predictions.</p>
<p><strong>Box 2: Clustering - Clustering, in machine learning, is a method of grouping data points into similar clusters. It is also called segmentation.</strong></p>
<p>Over the years, many clustering algorithms have been developed. Almost <strong>all clustering algorithms use the features of individual items to find similar items</strong>. For example, you might apply clustering to find similar people by demographics. You might use clusterin! with text analysis to group sentences with similar topics or sentiment.</p>
<p><strong>Box 3: Classification - Two-class classification provides the answer to simple two-choice questions such as Yes/No or True/False.</strong></p>
<p>88) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_35.png" title="Body image" /></p>
<p>89) Using Azure Machine Learning designer, you have just developed and deployed a machine learning model to predict a used car's price, given key pieces of information about the car. You are now ready to call the deployed model for predictions from an application you are building.</p>
<p>information do you need to make a price prediction using the deployed model? (Choose 2 answers)</p>
<ul>
<li><strong>A. The REST endpoint URL for the deployed model.</strong></li>
<li><strong>B. Authentication key.</strong></li>
<li>C. Resource group ID</li>
<li>D. Inference cluster name</li>
</ul>
<p><strong>Correct Answer: AB</strong></p>
<p>To invoke a deployed machine learning model, you will need the REST endpoint URL for the deployed model and the authentication key.</p>
<p>90) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_36.png" title="Body image" /></p>
<p>91) Which statements about Azure Speech Services capabilities are true? (Choose 2 answers)</p>
<ul>
<li>A. The Speech-to-Text service cannot recognize or moderate profanity in an input audio file.</li>
<li><strong>B. The Speech-to-Text API provides a batch transcript API that can be used to batch process larger audio files</strong>.</li>
<li><strong>C. When using the Text-to-Speech API, you can configure speech settings such as speed and volume.</strong></li>
<li>D. Speech Translation is available through both the SDK and the REST API</li>
</ul>
<p><strong>Correct Answer: BC</strong></p>
<p>The Speech-to-Text service can recognize profanity in an input audio file, and you can choose to keep it as-is, mask it, or remove it. The Speech-to-Text service offers a real-time synchronous API suitable for short audio files or an asynchronous batch API that can be used to process larger input files. Both The Text-to-Speech and Speech-to-Text APls support multiple languages.</p>
<p>When using the Text-to-Speech service, you can use the Speech Synthesis Markup Language (SSML) (an XML-based markup language) to define the synthesized speech settings for things like speaker volume and speed.</p>
<p>Finally, the speech translation service does not provide a REST API; it is only available with a SDK.</p>
<p>92) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_37.png" title="Body image" /></p>
<p>Should be <strong>feature engineering</strong></p>
<p>Feature engineering involves transforming raw data into features suitable for machine learning algorithms.  </p>
<p>One crucial step is to ensure that numeric variables have a similar scale. This process, often called normalization or standardization, prevents features with larger scales from dominating the model's learning process.</p>
<p>93) Which term completes the following definition of an Azure Machine Learning concept?</p>
<p>An ______ is a workflow you build to manage the data and modules used to train and evaluate a machine learning</p>
<ul>
<li>A. <strong>pipeline</strong></li>
<li>B. experiment</li>
<li>C. jupyter notebook</li>
<li>D. workspace</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>In Azure Machine Learning, a <strong>pipeline</strong> is a workflow you build to manage the data and modules used to train and evaluate a machine learning model.</p>
<p>94) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_38.png" title="Body image" /></p>
<p>95) Which of the following types of applications are a common consumer of Azure Cognitive Services' QnA Maker? (Choose 2 answers)</p>
<ul>
<li><strong>A. social media applications</strong></li>
<li><strong>B. chatbots</strong></li>
<li>C. lanquage translation applications</li>
<li>D. applications used to review and moderate content (text and audio)</li>
</ul>
<p><strong>Correct Answer: AB</strong></p>
<p>QnA Maker can be used as a knowledge base when building conversational clients often associated with social media applications and chatbots.</p>
<p>96) You have an Azure Machine Learning model that predicts product quality. The model has a training dataset that contains 50,000 records. A sample of the data is shown in the following table.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_39.png" title="Body image" /></p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_40.png" title="Body image" /></p>
<p>98) Which of the following is not a capability of the Azure Computer Vision service? (Choose 2 answers)</p>
<ul>
<li>A. Describe an image with a phrase or sentence.</li>
<li>B. Detect printed or handwritten text found in an image.</li>
<li><strong>C. Train a custom model to identify domain-specific entities in an image.</strong></li>
<li><strong>D. Extract text and key/value pairs from documents.</strong></li>
</ul>
<p>Correct Answer: CD</p>
<p>Of the capabilities listed, there are two that are not features offered by the <strong>Azure Computer Vision service</strong>:</p>
<ul>
<li>Train a custom model to identify domain-specific entities in an image</li>
<li>Extract text and key/value pairs from documents</li>
</ul>
<p>However, <strong>these capabilities do exist with other Azure Cognitive Services</strong>. For example, it is possible to train and publish a custom model to identify and locate domain-specific entities in an image using Azure Custom Vision services. </p>
<p>Also, you can use Form Recognizer to extract text and key/value pairs from documents.</p>
<p>99) Which two actions are performed during the data ingestion and data preparation stage of an Azure Machine Learning process? Each correct answer presents part of the solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li>A. Calculate the accuracy of the model.</li>
<li>B. Score test data by using the model.</li>
<li><strong>C. Combine multiple datasets.</strong></li>
<li>D. Use the model for real-time predictions.</li>
<li><strong>E. Remove records that have missing values.</strong></li>
</ul>
<p><strong>Correct Answer: CE</strong></p>
<p>ingestion ==&gt; data transformation/manipulation</p>
<ul>
<li>C. Combine multiple datasets.</li>
<li>E. Remove records that have missing values.</li>
</ul>
<p>100) You need to predict the animal population of an area.</p>
<p>Which Azure Machine Learning type should you use?</p>
<ul>
<li><strong>A. regression</strong></li>
<li>B. clustering</li>
<li>C. classification</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p><strong>Regression is a supervised machine learning technique used to predict numeric values.</strong></p>
<p>101） Which of the following are one of the Azure Cognitive Services six principles of responsible AI? (Choose 2 answers)</p>
<ul>
<li><strong>A. Transparency</strong></li>
<li><strong>B. Fairness</strong></li>
<li>C. Communication</li>
<li>D. Collaboration</li>
</ul>
<p>Correct Answer: AB</p>
<p>The Azure Cognitive Services six principles of responsible AI are:</p>
<ul>
<li>Fairness</li>
<li>Transparency</li>
<li>Inclusiveness</li>
<li>Accountability</li>
<li>Safety and Reliability</li>
<li>Security and Privacy</li>
</ul>
<p>102） Which two languages can you use to write custom code for Azure Machine Learning designer? Each correct answer presents a complete solution.</p>
<ul>
<li><strong>A. Python</strong></li>
<li><strong>B. R</strong></li>
<li>C. C#</li>
<li>D. Scala</li>
</ul>
<p>Correct Answer: AB</p>
<p>Use Azure Machine Learning designer for customizing using Python and R code.</p>
<p>103) For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_41.png" title="Body image" /></p>
<ul>
<li>Y - must be numeric for regression</li>
<li>N - labels are not required</li>
<li>N - may or may not be numeric, not must</li>
</ul>
<p><strong>Box 1: Yes -</strong></p>
<p>For regression problems, the label column must contain numeric data that represents the response variable. Ideally the numeric data represents a continuous scale.</p>
<p><strong>Box 2: No</strong>-</p>
<ul>
<li>
<p>K-Means Clustering -</p>
<ul>
<li>
<p>Because the K-means algorithm is an unsupervised learning method, a label column is optional</p>
</li>
<li>
<p>If your data includes a label, you can use the label values to guide selection of the clusters and optimize the model.</p>
</li>
<li>If your data has no label, the algorithm creates clusters representing possible categories, based solely on the data.</li>
</ul>
</li>
</ul>
<p><strong>Box 3: No -</strong></p>
<p>For classification problems, the label column must contain either categorical values or discrete values. Some examples might be a yes/no
rating, a disease classification code or name, or an income group. If you pick a noncategorical column, the component will return an error
during training.</p>
<p>104) You are building an application that allows you to search the transcripts of recorded conversations from your customer support call center. </p>
<p>Which Azure Cognitive Service would you use to convert audio from call center conversations into text?</p>
<ul>
<li><strong>A. Speech-to-Text</strong></li>
<li>B. Language Understanding (LUIS)</li>
<li>C. Translator</li>
<li>D. Text Analytics</li>
</ul>
<p>Correct Answer: A</p>
<p>The Azure Speech-to-Text service can convert audio files to text, and supports a variety of languages.</p>
<p>105） Your company wants to build a recycling machine for bottles. <strong>The recycling machine must automatically identify bottles of the correct shape and reject all other items</strong>.</p>
<p>Which type of AI workload should the company use?</p>
<ul>
<li>A. anomaly detection</li>
<li>B. conversational AI</li>
<li><strong>C. computer vision</strong></li>
<li>D. natural lanquage processing</li>
</ul>
<p>Correct Answer: C</p>
<p>Azure's Computer Vision service gives you access to advanced algorithms that process images and return information based on the visual features you're interested in. </p>
<p>For example, Computer Vision can determine whether an image contains adult content, find specific brands or objects, or find human faces.</p>
<p>106) For each of the following statements, select Yes if the statement is true. Otherwise, select No.
NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_42.png" title="Body image" /></p>
<p>107) In Azure Cognitive Services, what is a QnA knowledge base?</p>
<ul>
<li><strong>A. A data set that includes question and answer pairs.</strong></li>
<li>B. A data set that includes a list of utterances and intents.</li>
<li>C. A data set that includes a set of industry-specific terms and the corresponding definition.</li>
<li>D. A database that includes training data sets for a variety of conversational AI scenarios.</li>
</ul>
<p>Correct Answer: A</p>
<p>When you set up QnA Maker, you create a knowledge base that includes a set of question and answer pairs. </p>
<p>Each answer can have multiple forms of the same question. Once your QnA Maker service is deployed, it can take a user question as input and process it to determine the appropriate answer found in the knowledge base.</p>
<p>108) In which two scenarios can you use the <strong>Form Recognizer service?</strong> Each correct answer presents a complete solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li><strong>A. Extract the invoice number from an invoice</strong>.</li>
<li>B. Translate a form from French to English.</li>
<li>C. Find image of product in a catalog.</li>
<li><strong>D. Identify the retailer from a receipt.</strong></li>
</ul>
<p><strong>Correct Answer: AD</strong></p>
<p>109) Select the answer that correctly completes the sentence.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_43.png" title="Body image" /></p>
<p>110) You want to build a web-based application that uses conversational AI to answer a variety of user questions. Which Azure service is the best choice?</p>
<ul>
<li><strong>A. Azure Bot Service</strong></li>
<li>B. Translator</li>
<li>C. Text Analytics</li>
<li>D. Speech Translation</li>
</ul>
<p>Correct Answer: A</p>
<p>The Azure Bot Service provides the Bot Framework SDK and Bot Framework Composer to help teams build and deploy
bots. </p>
<p>A bot is a service capable of interacting with a user in a similar way to how the user would interact with another person. The purpose of a bot is to automate relatively simple and repetitive tasks so that human intervention is not needed.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_44.png" title="Body image" /></p>
<p>111)  You have a database that contains a list of employees and their photos. You are tagging new photos of the employees.</p>
<p>For each of the following statements select Yes if the statement is true. Otherwise, select No.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_45.png" title="Body image" /></p>
<p>112) You need to develop a mobile app for employees to scan and store their expenses while travelling.
Which type of computer vision should you use?</p>
<ul>
<li>A. semantic segmentation</li>
<li>B. image classification</li>
<li>C. object detection</li>
<li><strong>D. optical character recognition (OCR)</strong></li>
</ul>
<p>Azure's Computer Vision API includes Optical Character Recognition (OCR) capabilities that extract printed or
handwritten text from images. <strong>You can extract text from images, such as photos of license plates or containers with
serial numbers, as well as from documents - invoices, bills, financial reports, articles, and more.</strong></p>
<p>113) For each of the following statements, select Yes if the statement is true. Otherwise, select No.
NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_46.png" title="Body image" /></p>
<p><strong>Box 1: Yes -</strong></p>
<p>Custom Vision functionality can be divided into two features. Image classification applies one or more labels to an image. Object detection is similar, but it also returns the coordinates in the image where the applied label(s) can be found.</p>
<p><strong>Box 2: Yes -</strong></p>
<p>The Custom Vision service uses a machine learning algorithm to analyze images. You, the developer, submit groups of images that feature and lack the characteristics in question. You label the images yourself at the time of submission. </p>
<p>Then, the algorithm trains to this data and calculates its own accuracy by testing itself on those same images.</p>
<p><strong>Box 3: No-</strong></p>
<p>Custom Vision service can be used only on graphic files.</p>
<p>114) You are processing photos of runners in a race.</p>
<p>You need to read the numbers on the runners' shirts to identity the runners in the photos.</p>
<p>Which type of computer vision should you use?</p>
<ul>
<li>A. facial recognition</li>
<li><strong>B. optical character recognition (OCR)</strong></li>
<li>C. image classification</li>
<li>D. object detection</li>
</ul>
<p><strong>Correct Answer: B</strong></p>
<p>Optical character recognition (OCR) allows you to extract printed or handwritten text from images and documents.</p>
<p>115) Match the types of machine learning to the appropriate scenarios.</p>
<p>To answer, drag the appropriate machine learning type from the column on the left to its scenario on the right. Each
machine learning type may be used once, more than once, or not at all.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_47.png" title="Body image" /></p>
<p><strong>Box 1: Image classification -</strong></p>
<p>Image classification is a supervised learning problem: define a set of target classes (objects to identify in images), and train a model to recognize them using labeled example photos.</p>
<p><strong>Box 2: Obiect detection</strong> -</p>
<p>Object detection is a computer vision problem. While closely related to image classification, object detection performs image classification at a more granular scale. Object detection both locates and categorizes entities within images.</p>
<p><strong>Box 3: Semantic Segmentation -</strong></p>
<p>Semantic segmentation achieves fine-grained inference by making dense predictions inferring label for every pixel, so that pixel is labeled with the class of its enclosing object or region</p>
<p>116) You use drones to identify where weeds grow between rows of crops to send an instruction for the removal of the weeds.</p>
<p>This is an example of which type of computer vision?</p>
<ul>
<li><strong>A. object detection</strong></li>
<li>B. optical character recognition (OCR)</li>
<li>C. scene segmentation</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>Object detection is similar to tagging, but the API returns the bounding box coordinates for each tag applied. For example, if an image contains a dog, cat and person, the Detect operation will list those objects together with their coordinates in the image.</p>
<p>Incorrect Answers:</p>
<ul>
<li>
<p>B: Optical character recognition (OCR) allows you to extract printed or handwritten text from images and documents.</p>
</li>
<li>
<p>C: Scene segmentation determines when a scene changes in video based on visual cues. A scene depicts a single event and it's composed by a series of consecutive shots, which are semantically related.</p>
</li>
</ul>
<p>117) Match the facial recognition tasks to the appropriate questions.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_48.png" title="Body image" /></p>
<p>Box 1: verification -</p>
<p>Face verification: Check the likelihood that two faces belong to the same person and receive a confidence score.</p>
<p>Box 2: similarity.</p>
<p>Box 3: Grouping -</p>
<p>Box 4: identification -</p>
<p>Face detection: Detect one or more human faces along with attributes such as: age, emotion, pose, smile, and facial hair, including 27 landmarks for each face in the image.</p>
<p>118） Match the types of computer vision workloads to the appropriate scenarios.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_49.png" title="Body image" /></p>
<p><strong>Box 1: Facial recognition -</strong></p>
<p>Face detection that perceives faces and attributes in an image; <strong>person identification that matches an individual in your private repository of up to 1 million people</strong>; perceived emotion recognition that detects a range of facial expressions like happiness, contempt, neutrality, and fear; and recognition and grouping of similar faces in images.</p>
<p>119) You need to determine the location of cars in an image so that you can estimate the distance between the cars.</p>
<p>Which type of computer vision should you use?</p>
<ul>
<li>A. optical character recognition (OCR)</li>
<li><strong>B. object detection</strong></li>
<li>C. image classification</li>
<li>D. face detection</li>
</ul>
<p>Correct Answer: B</p>
<p>Object detection is similar to tagging, but the API returns the bounding box coordinates (in pixels) for each object found.</p>
<p>For example, if an image contains a dog, cat and person, the Detect operation will list those objects together with their coordinates in the image. </p>
<p>You can use this functionality to process the relationships between the objects in an image. It also lets you determine whether there are multiple instances of the same tag in an image.</p>
<p>The Detect API applies tags based on the objects or living things identified in the image. There is currently no formal relationship between the tagging taxonomy and the object detection taxonomy. At a conceptual level, the Detect API only finds objects and living things, while the Tag API can also include contextual terms like "indoor", which can't be localized with bounding boxes.</p>
<p>120) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_50.png" title="Body image" /></p>
<p><strong>Azure Custom Vision is a cognitive service that lets you build, deploy, and improve your own image classifiers</strong>. </p>
<p>An image classifier is an AI service that applies labels (which represent classes) to images, according to their visual characteristics. Unlike the Computer Vision service, Custom Vision allows you to specify the labels to apply.</p>
<p>Note: The Custom Vision service uses a machine learning algorithm to apply labels to images. You, the developer, must submit groups of images that feature and lack the characteristics in question. You label the images yourself at the time of submission.</p>
<p>Then the algorithm trains to this data and calculates its own accuracy by testing itself on those same images. Once the algorithm is trained, you can test, retrain, and eventually use it to classify new images according to the needs of your app. You can also export the model itself for offline use.</p>
<p>121) You send an image to a Computer Vision API and receive back the annotated image shown in the exhibit</p>
<p>Which type of computer vision was used?</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_51.png" title="Body image" /></p>
<ul>
<li><strong>A. object detection</strong></li>
<li>B. face detection</li>
<li>C. optical character recognition (OCR)</li>
<li>D. image classification</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p>Object detection is similar to tagging, but the API returns the bounding box coordinates (in pixels) for each object found. For
example, if an image contains a dog, cat and person, the Detect operation will list those objects together with their coordinates
in the image. You can use this functionality to process the relationships between the objects in an image. </p>
<p>It also lets you determine whether there are multiple instances of the same tag in an image.</p>
<p>The Detect API applies tags based on the objects or living things identified in the image. There is currently no formal
relationship between the tagging taxonomy and the object detection taxonomy. </p>
<p>At a conceptual level, the Detect API only finds objects and living things, while the Tag API can also include contextual terms like "indoor", which can't be localized with bounding boxes.</p>
<p>122) What are two tasks that can be performed by using the Computer Vision service? Each correct answer presents a complete solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li>A. Train a custom image classification model.</li>
<li><strong>B. Detect faces in an image</strong>.</li>
<li><strong>C. Recognize handwritten text</strong>.</li>
<li>D. Translate the text in an image between languages.</li>
</ul>
<p>Correct Answer: BC</p>
<p>B: Azure's Computer Vision service provides developers with access to advanced algorithms that process images and
return information based on the visual features you're interested in. </p>
<p>For example, Computer Vision can determine whether an image contains adult content, find specific brands or objects, or find human faces.</p>
<p>C: Computer Vision includes Optical Character Recognition (OCR) capabilities. You can use the new Read API to extract printed and handwritten text from images and documents.</p>
<p>123) What is a use case for classification?</p>
<ul>
<li>A. predicting how many cups of coffee a person will drink based on how many hours the person slept the previous night.</li>
<li>B. analyzing the contents of images and grouping images that have similar colors</li>
<li><strong>C. predicting whether someone uses a bicycle to travel to work based on the distance from home to work</strong></li>
<li>D. predicting how many minutes it will take someone to run a race based on past race times</li>
</ul>
<p><strong>Correct Answer: C</strong></p>
<p>Two-class classification provides the answer to simple two-choice questions such as Yes/No or True/False.</p>
<p>Incorrect Answers:</p>
<ul>
<li>A: This is Regression.</li>
<li>B: This is Clustering.</li>
<li>D: This is Regression.</li>
</ul>
<p>124) What are two tasks that can be performed by using computer vision? Each correct answer presents a complete solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li>A. Predict stock prices.</li>
<li><strong>B. Detect brands in an image.</strong></li>
<li><strong>C. Detect the color scheme in an image</strong></li>
<li>D. Translate text between languages.</li>
<li>E. Extract key phrases.</li>
</ul>
<p>Correct Answer: BC</p>
<p>B: Identify commercial brands in images or videos from a database of thousands of global logos. </p>
<p>You can use this feature, for example, to discover which brands are most popular on social media or most prevalent in media product placement.</p>
<p>C: Analyze color usage within an image. Computer Vision can determine whether an image is black &amp; white or color and, for color images, identify the dominant and accent colors.</p>
<p>125) You need to build an image tagging solution for social media that tags images of your friends automatically.</p>
<p>Which Azure Cognitive Services service should you use?</p>
<ul>
<li><strong>A. Face</strong></li>
<li>B. Form Recognizer</li>
<li>C. Text Analytics</li>
<li>D. Computer Vision</li>
</ul>
<p><strong>Correct Answer: A</strong></p>
<p><strong>The Azure Cognitive Services Face service provides facial recognition and analysis capabilities.</strong> </p>
<p><strong>It can detect and recognize faces in images, identify specific individuals, and analyze facial attributes such as age, gender, emotions, and more.</strong> </p>
<p>By training the Face service with images of your friends, you can create a custom face recognition model that will allow you to automatically tag images of your friends in social media. The Face service provides robust and accurate face detection and recognition capabilities, making it suitable for tasks like image tagging based on specific individuals.</p>
<p>126) In which two scenarios can you use the <strong>Form Recognizer</strong> service? Each correct answer presents a complete solution</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li><strong>A. Identify the retailer from a receipt</strong></li>
<li>B. Translate from French to English</li>
<li><strong>C. Extract the invoice number from an invoice</strong></li>
<li>D. Find images of products in a catalog</li>
</ul>
<p>Correct Answer: AC</p>
<p>127) DRAG DROP - Match the facial recognition tasks to the appropriate questions</p>
<p>To answer, drag the appropriate task from the column on the left to its question on the right. Each task may be used once, more tham once, or not at all.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_52.png" title="Body image" /></p>
<p><strong>Box 1: verification - Identity verification</strong></p>
<p>Modern enterprises and apps can use the Face identification and Face verification operations to verify that a user is who they claim to be.</p>
<p><strong>Box 2: similarity</strong> - The Find Similar operation does face matching between a target face and a set of candidate faces, finding a smaller set of faces that look similar to the target face. This is useful for doing a face search by image.</p>
<p>The service supports two working modes, matchPerson and matchFace. The matchPerson mode returns similar faces after filtering for the same person by using the Verify API. The matchFace mode ignores the same-person filter. It returns a list of similar candidate faces that mav or mav not belong to the same person.</p>
<p><strong>Box 3: identification</strong> - Face identification can address "one-to-many" matching of one face in an image to a set of faces in a secure repository. </p>
<p>Match candidates are returned based on how closely their face data matches the query face. This scapario is used in granting building or airport access to a certain group of people or verifying the user of a device.</p>
<p>128) Which Computer Vision feature can you <strong>use to generate automatic captions for digital photographs</strong>?</p>
<ul>
<li>A. Recognize text.</li>
<li>B. Identify the areas of interest.</li>
<li>C. Detect obiects.</li>
<li><strong>D. Describe the images.</strong></li>
</ul>
<p>Correct Answer: D</p>
<p><strong>automatic captions for digital photographs =&gt; generate automatic captions</strong></p>
<p><strong>Describe images with human-readable language Computer Vision can analyze an image and generate a human-readable phrase that describes its contents</strong>.</p>
<p>The algorithm returns several descriptions based on different visual features, and each description is given a confidence score. </p>
<p>The final output is a list of descriptions ordered from highest to lowest confidence.
The image description feature is part of the Analyze Image API.</p>
<p>129) Which service should you use to extract text, key/value pairs, and table data automatically from scanned documents?</p>
<ul>
<li>A. Custom Vision</li>
<li>B. Face</li>
<li><strong>C. Form Recognizer</strong></li>
<li>D. Language</li>
</ul>
<p>Correct Answer: C</p>
<p>Form Recognizer applies advanced machine learning to accurately extract text, key-value pairs, tables, and structures from documents.</p>
<p>130) Select the answer that correctly completes the sentence.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_53.png" title="Body image" /></p>
<p>Handwriting OCR (optical character recognition) is the process of automatically extracting handwritten information from paper, scans and other low-quality digital documents.</p>
<p>131) You are developing a solution that uses the Text Analytics service.</p>
<p>You need to identify the main talking points in a collection of documents.
Which type of natural language processing should you use?</p>
<ul>
<li>A. entity recognition</li>
<li><strong>B. key phrase extraction</strong></li>
<li>C. sentiment analysis</li>
<li>D. language detection</li>
</ul>
<p>Correct Answer: B</p>
<p>Broad entity extraction: Identify important concepts in text, including key</p>
<p>Key phrase extraction/ Broad entity extraction: Identify important concepts in text, including key phrases and named entities such as people, places, and organizations.</p>
<p>132) In which two scenarios can you use <strong>speech recognition</strong>? Each correct answer presents a complete solution.</p>
<ul>
<li>A. an in-car system that reads text messages aloud</li>
<li><strong>B. providing closed captions for recorded or live videos</strong></li>
<li>C. creating an automated public address system for a train station</li>
<li><strong>D. creating a transcript of a telephone call or meeting</strong></li>
</ul>
<p><strong>Correct Answer: BD</strong></p>
<p>133) To complete the sentence, select the appropriate option in the answer area.</p>
<p>Hot Area:</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_54.png" title="Body image" /></p>
<p>Speech recognition = speech to text
Speech synthesis = text to speech</p>
<p>134) You need to build an app that will read recipe instructions aloud to support users who have reduced vision. </p>
<p>Which version service should you use?</p>
<ul>
<li>A. Text Analytics</li>
<li>B. Translator</li>
<li><strong>C. Speech</strong></li>
<li>D. Language Understanding (LUIS)</li>
</ul>
<p><strong>Speech, a managed service offering industry-leading speech capabilities such as speech-to-text, text-to-speech, speech translation, and speaker recognition</strong></p>
<p>135) HOTSPOT</p>
<p>For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_55.png" title="Body image" /></p>
<p>136) Your website has a chatbot to assist customers.</p>
<p>You need to detect when a customer is upset based on what the customer types in the chatbot.</p>
<p>Which type of AI workload should you use?</p>
<ul>
<li>A. anomaly detection</li>
<li>B. computer vision</li>
<li>C. regression</li>
<li><strong>D. natural language processing</strong></li>
</ul>
<p>Natural language processing (NLP) is used for tasks such as sentiment analysis, topic detection, language detection,key phrase extraction, and document categorization.</p>
<p>Sentiment Analysis is the process of determining whether a piece of writing is positive, negative or neutral.</p>
<p>137) You plan to <strong>develop a bot</strong> that will enable users to query a knowledge base by using natural language processing.</p>
<p>Which two services should you include in the solution? Each correct answer presents part of the solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li><strong>A. QnA Maker</strong></li>
<li><strong>B. Azure Bot Service</strong></li>
<li>C. Form Recognizer</li>
<li>D. Anomaly Detector</li>
</ul>
<p>Correct Answer: AB</p>
<p>138）which two scenarios can you use <strong>a speech synthesiss solution</strong>？ Each correct answer presents a complete solution.</p>
<ul>
<li><strong>A.an automated voice that reads back a credit card number entered into a telephone by using a numeric keypad</strong></li>
<li>B.generating live captions for a news broadcast</li>
<li>C.extracting key phrases from the audio recording of a meeting</li>
<li><strong>D.an AI character in a computer game that Speaks audibly to a player</strong></li>
</ul>
<p>Correct Answer:AD</p>
<p><strong>Azure Text to Speech is a Speech service feature that converts text to life like speech.</strong></p>
<p>Incorrect Answers:</p>
<p><strong>C: Extracting key phrases is not speech synthesis</strong></p>
<p>139)  For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_56.png" title="Body image" /></p>
<p>The translator service provides multi-language support for text translation, transliteration, language detection, and dictionaries </p>
<p>Speech-to-Text, also known as automatic speech recognition (ASR), is a feature of Speech Services that provides transcription.</p>
<p>NLP enables you to create software that can:</p>
<ul>
<li>Analyze text documents to extract key phrases and recognize entities (such as places, dates, or people). ie Text Analytics service</li>
<li>Perform sentiment analysis to determine how positive or negative the language used in a document is. ie Text Analytics service</li>
<li>Interpret spoken language, and synthesize speech responses. ie Speech service(speech to text and text to speech)</li>
<li>Automatically translate spoken or written phrases between languages. ie Text service(for text to text translation)/Speech service(for speech to
text/speech translation)</li>
</ul>
<p>Interpret commands and determine appropriate actions. ie Language Understanding(LUIS) service</p>
<p>140) DRAG DROP</p>
<p>You need to scan the news for articles about your customers and alert employees when there is a negative article. Positive articles must be added to a press book.</p>
<p>Which natural language processing tasks should you use to complete the process? To answer, drag the appropriate tasks to the correct locations. Each task may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_57.png" title="Body image" /></p>
<p><strong>Box 1: Entity recognition -</strong></p>
<p>the Named Entity Recognition module in Machine Learning Studio (classic), to identify the names of things, such as people, companies, or locations in a column of text.</p>
<p>Named entity recognition is an important area of research in machine learning and natural language processing (NLP), because it can be used
to answer many real-world questions, such as:</p>
<ul>
<li>✑ Which companies were mentioned in a news article?</li>
<li>✑ Does a tweet contain the name of a person? Does the tweet also provide his current location?</li>
<li>✑ Were specified products mentioned in complaints or reviews?</li>
</ul>
<p><strong>Box 2: Sentiment Analysis -</strong></p>
<p>The Text Analytics API's Sentiment Analysis feature provides two ways for detecting positive and negative sentiment. If you send a Sentiment
Analysis request, <strong>the API will return sentiment labels (such as "negative", "neutral" and "positive") and confidence scores at the sentence and document-level</strong></p>
<p>141) You are building a knowledge base by using QnA Maker.</p>
<p>Which file format can you use to populate the knowledge base?</p>
<ul>
<li>A. PPTX</li>
<li>B. XML</li>
<li>C. ZIP</li>
<li><strong>D. PDF</strong></li>
</ul>
<p>Correct Answer: D</p>
<p>D: Content types of documents you can add to a knowledge base:</p>
<p><strong>Content types include many standard structured documents such as PDF, DOC, and TXT.</strong></p>
<p>Note: The tool supports the following file formats for ingestion:</p>
<ul>
<li><code>tsv</code>: QnA contained in the format Ouestion(tab)Answer.</li>
<li><code>.txt</code>,<code>.docx</code>,<code>.pdf</code>: QnA contained as regular FAO content-that is, a sequence of questions and answers.</li>
</ul>
<p>Incorrect Answers</p>
<ul>
<li>A: PPTX is the default presentation file format for new PowerPoint presentations.</li>
<li>B: It is not possible to ingest xml file directly.</li>
</ul>
<p>142) In which scenario should you use key phrase extraction?</p>
<ul>
<li>A. identifying whether reviews of a restaurant are positive or negative</li>
<li>B. generating captions for a video based on the audio track</li>
<li><strong>C. identifying which documents provide information about the same topics</strong></li>
<li>D. translating a set of documents from English to German</li>
</ul>
<p>Correct Answer: C</p>
<p>143) You have insurance claim reports that are stored as text.</p>
<p><strong>You need to extract key terms from the reports to generate summaries</strong>.</p>
<p>Which type of AI workload should you use?</p>
<ul>
<li><strong>A. natural language processing</strong></li>
<li>B. conversational AI</li>
<li>C. anomaly detection</li>
<li>D. computer vision</li>
</ul>
<p>Correct Answer: A</p>
<p>144) To complete the sentence, select the appropriate option in the answer area.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_58.png" title="Body image" /></p>
<p>Natural language processing (LP) is used for tasks such as sentiment analysis, topic detection, language detection, key phrase extraction, and document categorization.</p>
<p>145) Which AI service can you use to <strong>interpret the meaning</strong> of a user input such as Call me back later?</p>
<ul>
<li>A. Translator</li>
<li>B. Text Analytics</li>
<li>C. Speech</li>
<li><strong>D. Language Understanding (LUIS)</strong></li>
</ul>
<p>Correct Answer: D</p>
<p>Language Understanding (LUIS) is a cloud-based AI service, that applies custom machine-learning intelligence to a user's conversational, natural language text to predict overall meaning, and pull out relevant, detailed information.</p>
<p>146) You are developing a chatbot solution in Azure.</p>
<p>Which service should you use to determine a user's intent?</p>
<ul>
<li>A. Translator</li>
<li>B. QnA Maker</li>
<li>C. Speech</li>
<li><strong>D. Language Understanding (LUIS)</strong></li>
</ul>
<blockquote>
<p><strong>correct but now LUIS has been replaced by CLU (Conversational Language Understanding)</strong></p>
</blockquote>
<p>Language Understanding (LUIS) is a cloud-based API service that applies custom machine-learning intelligence to a user's conversational, natural language text to predict overall meaning, and pull out relevant, detailed information.</p>
<p>Design your LUIS model with categories of user intentions called intents. Each intent needs examples of user utterances. Each utterance can provide data that needs to be extracted with machine-learning entities.</p>
<p>147) You need to make the written press releases of your company available in a range of languages.</p>
<p>Which service should you use?</p>
<ul>
<li><strong>A. Translator</strong></li>
<li>B. Text Analytics</li>
<li>C. Speech</li>
<li>D. Language Understanding (LUIS)</li>
</ul>
<p>Translator, an AI service for real-time document and text translation</p>
<p>Translate text instantly or in batches across more than 100 languages, powered by the latest innovations in machine translation. Support a wide
range of use cases, such as translation for call centers, multilingual conversational agents, or in-app communication.</p>
<p>Translator is a cloud-based machine translation service you can use to translate text in near real-time through a simple REST API call.</p>
<p>The service uses modern neural machine translation technology and offers statistical machine translation technology. </p>
<p>Custom Translator is an extension of Translator, which allows you to build neural translation systems.</p>
<p>148 For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_59.png" title="Body image" /></p>
<ul>
<li>The Language service can identify in which language text is written.   （<strong>Yes</strong>)</li>
<li>The Language service can detect handwritten signatures in a document.  （<strong>NO</strong>)</li>
<li>The Language service can identify companies and organizations mentioned in a document.  （<strong>Yes</strong>)</li>
</ul>
<p><strong>Particularly for the Text Analytics service we need to remember that it is primarily focused on analyzing and extracting insights from textual data, such as sentiment analysis, key phrase extraction, language detection, and named entity recognition</strong>. It processes structured and unstructured text to derive meaningful information and patterns.</p>
<p>The Text Analytics API is a cloud-based service that provides advanced natural language processing over raw text, and includes four main functions: <strong>sentiment analysis, key phrase extraction, named entity recognition, and language detection</strong>.</p>
<p>To detect and extract handwritten signatures from documents, you would need to utilize other services or techniques specifically designed for
handwriting recognition or optical character recognition (OCR). Azure provides services like Azure Form Recognizer and Azure Cognitive Services - Computer Vision, which include OCR capabilities and can be used to extract text and recognize handwriting from scanned documents or images</p>
<p><strong>Box 1: Yes -</strong></p>
<p>You can detect which lanquage the input text is written in and report a single language code for every document submitted on the request in a wide range of languages, variants, dialects, and some regional/cultural languages. The language code is paired with a score indicating the strength of the score.</p>
<p><strong>Box 2: No -</strong></p>
<p><strong>Handwritten detection is part of OCR (Optical Character Recognition).</strong></p>
<p>Box 3: Yes -</p>
<p>Azure Cognitive Service for Language provides features including</p>
<p>Named Entity Recognition (NER): This pre-configured feature identifies entities in text across several pre-defined categories.</p>
<p>Note: Named entity recognition is a natural language processing technique that can automatically scan entire articles and pull out some
fundamental entities in a text and classify them into predefined
categories. Entities may be,</p>
<ul>
<li>Organizations,</li>
<li>Quantities,</li>
<li>Monetary values,</li>
<li>Percentages, and more</li>
</ul>
<p>149) Match the types of natural language processing workloads to the appropriate scenarios
To answer, drag the appropriate workload type from the column on the left to its scenario on the right. Each workload type may be used once, more than once, or not at all.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_60.png" title="Body image" /></p>
<p>Box 1: Entity recognition -</p>
<p><strong>Named Entity Recognition (NER) is the ability to identify different entities in text and categorize them into pre-defined classes or types</strong> such as: person, location, event, product, and organization.</p>
<p><strong>Box 2: Sentiment analysis</strong> -</p>
<p><strong>Sentiment Analysis is the process of determining whether a piece of writing is positive, negative or neutral.</strong></p>
<p>150)  For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_61.png" title="Body image" /></p>
<p><strong>Box 1: Yes -</strong></p>
<p>Content Moderator is part of Microsoft Cognitive Services allowing businesses to use machine assisted moderation of text, images, and videos that augment human review.</p>
<p>The text moderation capability now includes a new machine-learning based text classification feature which uses a trained model to identify
possible abusive, derogatory or discriminatory language such as slang, abbreviated words, offensive, and intentionally misspelled words for review.</p>
<p>Box 2: No -</p>
<p>Azure's Computer Vision service gives you access to advanced algorithms that process images and return information based on the visual
features you're interested in. For example, Computer Vision can determine whether an image contains adult content, find specific brands or objects, or find human faces</p>
<p>Box 3: Yes -</p>
<p><strong>Natural language processing (NLP) is used for tasks such as sentiment analysis, topic detection, language detection, key phrase extraction, and document categorization</strong>.</p>
<p>Sentiment Analysis is the process of determining whether a piece of writing is positive, negative or neutral</p>
<p>151) You are developing a natural language processing solution in Azure. The solution will analyze customer reviews and determine how positive or negative each review is.</p>
<p>This is an example of which type of natural language processing workload?</p>
<ul>
<li>A. language detection</li>
<li><strong>B. sentiment analysis</strong></li>
<li>C. key phrase extraction</li>
<li>D. entity recognition</li>
</ul>
<p><strong>Correct Answer: B</strong></p>
<p>Sentiment Analysis is the process of determining whether a piece of writing is positive, negative or neutral.</p>
<p>152) You use natural language processing to process text from a Microsoft news story.
You receive the output shown in the following exhibit.</p>
<p>Which type of natural languages processing was performed?</p>
<ul>
<li><strong>A. entity recognition</strong></li>
<li>B. key phrase extraction</li>
<li>C. sentiment analysis</li>
<li>D. translation</li>
</ul>
<p><img alt="Alt Image Text" src="../../images/ai900_2_62.png" title="Body image" /></p>
<p>Correct Answer: A</p>
<p><strong>Named Entity Recognition (NER) is the ability to identify different entities in text and categorize them into pre-defined classes or types such as: person, location, event, product, and organization.</strong></p>
<p>In this question, the square brackets indicate the entities such as DateTime, PersonType, Skill.</p>
<p>153) You are using Azure Machine Learning to develop a model to predict whether a potential borrower is likely to default on a loan. The following confusion matrix describes the performance of one of your models (predicted outcome across the top, true value top to bottom)</p>
<p>Which statement about these results is true? (Choose 2 answers)</p>
<ul>
<li><strong>A. There were 35 false negatives</strong>.</li>
<li>B. There were 11 false negatives.</li>
<li><strong>C. There were 11 false positives.</strong></li>
<li>D. There were 11 true positives.</li>
</ul>
<p>Correct Answer: AC</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_63.png" title="Body image" /></p>
<p>154) You are using Azure Machine Learning to develop a machine learning model to <strong>predict fuel efficiency (miles/gallon) for automobiles</strong> manufactured between 2000 and 2010. The following information is provided for each automobile in the dataset:</p>
<pre><code>mpg (miles per gallon) | number of cylinders | horsepower | weight | model year | car name
</code></pre>
<p>Currently, the car name includes both the manufacturer and the car model (ex. "honda civic"). You would like to break the car name into two separate pieces of data (columns): manufacturer and model. What is the term used to describe this type of data processing before training a model?</p>
<ul>
<li><strong>A. feature engineering</strong></li>
<li>B. feature selection</li>
<li>C. normalization</li>
<li>D. data splitting</li>
</ul>
<p>Correct Answer: A</p>
<p>The scenario given is this problem is an example of feature engineering. <strong>Feature engineering is a process where new features are created by transforming raw data</strong>. Feature engineering, normalization, and data splitting are examples of three common data transformation steps taken before training a machine learning model. If you are not familiar with normalization, take a look at the documentation for the Normalization module. Normalizing data can be an important step when preparing data to train a model.</p>
<p>155) You are using Azure Machine Learning to develop a machine learning model to predict fuel efficiency (miles/gallon) for automobiles manufactured between 2000 and 2010. The following information is provided for each automobile in the dataset:</p>
<ul>
<li>mpg (miles per gallon)</li>
<li>number of cylinders</li>
<li>horsepower</li>
<li>weight</li>
<li>model year</li>
<li>manufacturer</li>
<li>car name (model)</li>
</ul>
<p>Which of the following statements about the data set and machine learning model are correct? (Choose 2 answers)</p>
<ul>
<li><strong>A. MPG (miles per gallon) is the label for this machine learning model.</strong></li>
<li>B. MPG (miles per gallon) is a <strong>feature</strong> for this machine learning model.</li>
<li>C. The car name (model) is the <strong>label</strong> for this machine learning model.</li>
<li>D. The manufacturer is an example of a potential <strong>feature</strong> for this machine learning model.</li>
</ul>
<p>156) You plan to apply Text Analytics API features to a technical support ticketing system.</p>
<p>Match the Text Analytics API features to the appropriate natural language processing scenarios.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_64.png" title="Body image" /></p>
<p>Box1: Sentiment analysis - Sentiment Analysis is the process of determining whether a piece of writing is positive, negative or neutral.</p>
<p>Box 2: Broad entity extraction - Broad entity extraction: Identify important concepts in text, including key
Key phrase extraction/ Broad entity extraction: Identify important concepts in text, including key phrases and named entities such as people, places, and organizations.</p>
<p>Box 3: Entity Recognition - Named Entity Recognition: Identify and categorize entities in your text as people, places, organizations, date/time, quantities, percentages, currencies, and more.</p>
<p>Well-known entities are also recognized and linked to more information on the web.</p>
<p>157) You are authoring a Language Understanding (LUIS) application to support a music festival.
You want users to be able to ask questions about scheduled shows, such as: Which act is playing on the main stage?'</p>
<p>The question Which act is playing on the main stage?" is an example of which type of element?</p>
<ul>
<li>A. an intent</li>
<li><strong>B. an utterance</strong></li>
<li>C. a domain</li>
<li>D. an entity</li>
</ul>
<p>Correct Answer: B</p>
<p><strong>Utterances are input from the user that your app needs to interpret</strong>.</p>
<p>158) You build a QnA Maker bot by using a frequently asked questions (FAQ) page.</p>
<p>You need to add professional greetings and other responses to make the bot more user friendly.</p>
<p>What should you do?</p>
<ul>
<li>A. Increase the confidence threshold of responses</li>
<li>B. Enable active learning</li>
<li>C. Create multi-turn questions</li>
<li><strong>D. Add chit-chat</strong></li>
</ul>
<p>Correct Answer: D</p>
<p>159) You need to develop a chatbot for a website. The chatbot must answer users' questions based on the information in the following documents:</p>
<ul>
<li>A product troubleshooting guide in a Microsoft Word document</li>
<li>A frequently asked questions (FAQ) list on a webpage</li>
</ul>
<p>Which service should you use to process the documents?</p>
<ul>
<li>A. Azure Bot Service</li>
<li>B. Language Understanding</li>
<li>C. Text Analytics</li>
<li><strong>D. QnA Maker</strong></li>
</ul>
<p>Correct Answer: D</p>
<p>160) You are building a Language Understanding model for an e-commerce business.</p>
<p>You need to ensure that the model detects when utterances are outside the intended scope of the model.</p>
<p>What should you do?</p>
<ul>
<li>A. Test the model by using new utterances</li>
<li><strong>B. Add utterances to the None intent</strong></li>
<li>C. Create a prebuilt task entity</li>
<li>D. Create a new model</li>
</ul>
<p>Correct Answer: B</p>
<p><strong>The None intent is filled with utterances that are outside of your  principle of the domain</strong></p>
<p><strong>Utterances are input from the user that your app needs to interpret</strong>.</p>
<p><strong>None intent</strong></p>
<p>The None intent is created but left empty on purpose. The None intent is a required intent and can't be deleted or renamed. Fill it with utterances that are outside of your domain.</p>
<p>The None intent is the fallback intent, and should have 10% of the total utterances. It is important in every app, because it’s used to teach LUIS utterances that are not important in the app domain (subject area). If you do not add any utterances for the None intent, LUIS forces an utterance that is outside the domain into one of the domain intents. This will skew the prediction scores by teaching LUIS the wrong intent for the utterance.</p>
<p>When an utterance is predicted as the None intent, the client application can ask more questions or provide a menu to direct the user to valid choices.</p>
<h2 id="topic-2">Topic 2</h2>
<p>161） When developing an AI system for self-driving cars, the Microsoft  ___ principle for responsible AI should be applied to ensure consistent operation of the system during <strong>unexpected circumstances.</strong></p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_65.png" title="Body image" /></p>
<p><strong>Reliability and safety</strong></p>
<p>Reliability and safety: To build trust, it's critical that Al systems operate reliably, safely, and consistently under normal circumstances and in unexpected conditions.</p>
<p>These systems should be able to operate as they were originally designed, respond safely to unanticipated conditions, and resist harmful manipulation.</p>
<p>162  __  used to extract dates, quantities, and locations from text.</p>
<ul>
<li>Key phrase extraction</li>
<li>Language detection</li>
<li><strong>Named Entity Recognition (NER)</strong></li>
<li>Sentiment Analysis</li>
</ul>
<p><strong>The NER feature can identify and categorize entities in unstructured text. For example: people, places, organizations, and quantities.</strong></p>
<p>163 Returning a <strong>bounding box that indicates the location</strong> of a vehicle in an
image is an example of  ____</p>
<ul>
<li>image classification.</li>
<li><strong>object detection.</strong></li>
<li>optical character recognizer (OCR).</li>
<li>semantic segmentation.</li>
</ul>
<p>164  Match the principles of responsible AI to appropriate requirements.</p>
<ul>
<li>The system must not discriminate based on gender, race (<strong>Fairness</strong>)</li>
<li>Personal data must be visible only to approve (<strong>Privacy and security</strong>)</li>
<li>Automated decision-making processes must be recorded so that approved users can identify why a decision was made(<strong>Transparency</strong>)</li>
</ul>
<p>165 You are <strong>evaluating whether to use a basic workspace or an enterprise workspace</strong> in Azure Machine Learning.</p>
<p>What are two tasks that require an enterprise workspace? Each correct answer presents a complete solution.</p>
<ul>
<li><strong>A. Use a graphical user interface (GUI) to run automated machine learning experiment</strong>s.</li>
<li>B. Create a compute instance to use as a workstation.</li>
<li><strong>C. Use a graphical user interface (GUI) to define and run machine learning experiments from Azure Machine Learning designer.</strong></li>
<li>D. Create a dataset from a comma-separated value (CSV) file.</li>
</ul>
<p>166 Which two scenarios are examples of a <strong>natural language processing workload</strong>? Each correct answer presents a complete solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li>A. monitoring the temperature of machinery to turn on a fan when the temperature reaches a specific threshold</li>
<li><strong>B. a smart device in the home that responds to questions such as, "What will the weather be like today?"</strong></li>
<li><strong>C. a website that uses a knowledge base to interactively respond to users' questions</strong></li>
<li>D. assembly line machinery that autonomously inserts headlamps into cars</li>
</ul>
<blockquote>
<p><strong>You have an AI solution that provides users with the ability to control smart devices by using verbal commands</strong></p>
</blockquote>
<p>167 You have an AI solution that provides users with the ability to control smart devices by <strong>using verbal commands</strong>.</p>
<p>Which two types of natural language processing (NLP) workloads does the solution use? </p>
<p>Each correct answer presents part of the solution</p>
<ul>
<li>A. text-to-speech</li>
<li>B. key phrase extraction</li>
<li><strong>C. speech-to-text</strong></li>
<li><strong>D. language modeling</strong></li>
<li>E. translation</li>
</ul>
<blockquote>
<ul>
<li>
<p>C. Speech to text</p>
</li>
<li>
<p>D. Natural language understanding (NLU)</p>
</li>
</ul>
</blockquote>
<p><strong>Text-to-Speech (TTS):</strong></p>
<p>TTS is a critical component that converts written text into spoken language. It enables the system to communicate with users by generating human-like speech from textual input1.</p>
<p><strong>Speech-to-Text (STT):</strong></p>
<p>STT, also known as Automatic Speech Recognition (ASR), performs the opposite function. It transcribes spoken language into written text, allowing the system to understand and process verbal commands</p>
<p>168 You plan to use Azure Cognitive Services to develop a voice controlled personal assistant app.</p>
<p>Match the Azure Cognitive Services to the appropriate tasks.</p>
<p>To answer, drag the appropriate service from the column on the left to its description on the right. Each service may be used once, more than once, or not at all</p>
<ul>
<li>Convert a user's speech to text   <strong>(Speech)</strong></li>
<li>Identify a user's intent    <strong>Language service</strong></li>
<li>Provide a spoken response to the user    <strong>Speech</strong></li>
</ul>
<p><strong>Box 1: Speech -</strong></p>
<p>The Speech service provides speech-to-text and text-to-speech capabilities with an Azure Speech resource. </p>
<p>You can transcribe speech to text with high accuracy, produce natural-sounding text-to-speech voices, translate spoken audio, and use speaker recognition during conversations</p>
<p>Box 2: Language service -</p>
<p>Build applications with conversational language understanding, a Cognitive Service for Language feature that understands natural language to interpret user goals and extracts key information from conversational phrases. </p>
<p>Create multilingual, customizable intent classification and entity extraction models for your domain- specific keywords or phrases across 96 languages</p>
<p>169 You have a webchat bot that provides responses from a QnA Maker knowledge base.</p>
<p>You need to ensure that the bot uses user feedback to improve the relevance of the responses over time.</p>
<p>What should you use?</p>
<ul>
<li>A. key phrase extraction</li>
<li>B. sentiment analysis</li>
<li>C. business logic</li>
<li><strong>D. active learning</strong></li>
</ul>
<p>Correct Answer: D</p>
<p><strong>Active learning.</strong></p>
<ul>
<li>1.Bot gets the answer from the knowledge base with the GenerateAnswer API, using the top property to get a number of answers.</li>
<li>2.Bot determines explicit feedback: <strong>Using your own custom business logic, filter out lo scores. In the bot or client-application, display list of possible answers to the user and get user's selected answer.</strong></li>
<li>3.Bot sends selected answer back to QnA Maker with the Train API.</li>
</ul>
<p>170 You are developing a conversational AI solution that will communicate with users through multiple channels including email, Microsoft Teams, and webchat.</p>
<p>Which service should you use?</p>
<ul>
<li>A. Text Analytics</li>
<li><strong>B. Azure Bot Service</strong></li>
<li>C. Translator</li>
<li>D. Form Recognizer</li>
</ul>
<p>171 For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<ul>
<li>A bot that responds to queries by internal users is an example of a conversational Al workload.   （<strong>Yes</strong>)</li>
<li>An application that displays images relating to an entered search term is an example of a conversational Al workload.     （<strong>No</strong>)</li>
<li>A web form used to submit a request to reset a password is an example
of a conversational Al workload.   (<strong>No</strong>)</li>
</ul>
<p>172.You need to provide content for a business chatbot that will help answer simple user queries.</p>
<p>What are three ways to create question and answer text by using QnA Maker? Each correct answer presents a complete solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li><strong>A. Generate the questions and answers from an existing webpage</strong>.</li>
<li>B. Use automated machine learning to train a model based on a file that contains the questions.</li>
<li><strong>C. Manually enter the questions and answers.</strong></li>
<li>D. Connect the bot to the Cortana channel and ask questions by using Cortana.</li>
<li><strong>E. Import chit-chat content from a predefined data source</strong>.</li>
</ul>
<p>173.<strong>You have a frequently asked questions (FAQ) PDF file</strong>.</p>
<p>You need to create a conversational support system based on the FAQ.</p>
<p>Which service should you use?</p>
<ul>
<li><strong>A. QnA Maker</strong></li>
<li>B. Text Analytics</li>
<li>C. Computer Vision</li>
<li>D. Language Understanding (LUIS)</li>
</ul>
<p>QnA Maker is a cloud-based API service that lets you create a conversational question-and-answer layer over your existing data. </p>
<p>Use it to build a knowledge base by extracting questions and answers from your semi-structured content, including FAQs, manuals, and documents.</p>
<p>173.You need to reduce the load on telephone operators by implementing a chatbot to answer simple questions with predefined answers.</p>
<p>Which two AI service should you use to achieve the goal? Each correct answer presents part of the solution.</p>
<p>NOTE: Each correct selection is worth one point</p>
<ul>
<li>A. Text Analytics</li>
<li><strong>B. QnA Maker</strong></li>
<li><strong>C. Azure Bot Service</strong></li>
<li>D. Translator</li>
</ul>
<p>Bots are a popular way to provide support through multiple communication channels. You can use the QnA Maker service and Azure Bot Service to create a bot that answers user questions</p>
<p>173-1 You need to reduce the load on telephone operators by implementing a chatbot to answer simple questions with predefined answers.</p>
<p>Which two AI services should you use to achieve the goal? Each correct answers presents part of the solution</p>
<ul>
<li>A. Azure Machine Learning</li>
<li><strong>B. Azure Bot Service</strong></li>
<li><strong>C. Language Service</strong></li>
<li>D. Translator</li>
</ul>
<p>B. Azure Bot Service - Azure Bot Service is a platform for creating and managing chatbots, making it a suitable choice for building a chatbot to handle simple questions.</p>
<p>C. Language Service - Language services, including natural language processing capabilities, are essential for understanding user questions and providing relevant responses. This can be integrated into your chatbot to improve its conversational abilities.</p>
<p>174.Which two scenarios are examples of a conversational AI workload? Each correct answer presents a complete solution.</p>
<p>NOTE: Each correct selection is worth one point</p>
<ul>
<li><strong>A. a smart device in the home that responds to questions such as What will the weather be like today?</strong></li>
<li><strong>B. a website that uses a knowledge base to interactively respond to users' questions</strong></li>
<li>C. assembly line machinery that autonomously inserts headlamps into cars</li>
<li>D. monitoring the temperature of machinery to turn on a fan when the temperature reaches a specific threshold、</li>
</ul>
<p>175.You have the process shown in the following exhibit.</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_66.png" title="Body image" /></p>
<p>Which type of AI solution is shown in the diagram?</p>
<ul>
<li>A. a sentiment analysis solution</li>
<li><strong>B. a chatbot</strong></li>
<li>C. a machine learning model</li>
<li>D. a computer vision application</li>
</ul>
<p>176.You need to develop a web-based AI solution for a customer support system. Users must be able to interact with a web app that will guide them to the best resource or answer.</p>
<p>Which service should you use?</p>
<ul>
<li>A. Custom Vision</li>
<li><strong>B. QnA Maker</strong></li>
<li>C. Translator Text</li>
<li>D. Face</li>
</ul>
<p>QnA Maker is a cloud-based API service that lets you create a conversational question-and-answer layer over your existing data. Use it to build
a knowledge base by extracting questions and answers from your semi-structured content, including FAQs, manuals, and documents. Answer
users' questions with the best answers from the QnAs in your knowledge baseג€"automatically. Your knowledge base gets smarter, too, as it
continually learns from user behavior</p>
<p>177 Which AI service should you use to create a bot from a frequently asked questions (FAQ) document?</p>
<ul>
<li><strong>A. QnA Maker</strong></li>
<li>B. Language Understanding (LUIS)</li>
<li>C. Text Analytics</li>
<li>D. Speech</li>
</ul>
<p>178 Which scenario is an example of a webchat bot?</p>
<ul>
<li>A. Determine whether reviews entered on a website for a concert are positive or negative, and then add a thumbs up or thumbs down emoji to</li>
<li>the reviews.</li>
<li>B. Translate into English questions entered by customers at a kiosk so that the appropriate person can call the customers back.</li>
<li>C. Accept questions through email, and then route the email messages to the correct person based on the content of the message.</li>
<li><strong>D. From a website interface, answer common questions about scheduled events and ticket purchases for a music festival.</strong></li>
</ul>
<p>179 For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<ul>
<li>You can use QnA Maker to query an Azure SQL database.   (No)</li>
<li>You should use QnA Maker when you want a knowledge base to provide the same answer to different users who submit similar questions. (Yes)</li>
<li>The QnA Maker service can determine the intent of a user utterance. (No)</li>
</ul>
<p>180 Which two scenarios are examples of a conversational AI workload? Each correct answer presents a complete solution.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li>A. a telephone answering service that has a pre-recorder message</li>
<li><strong>B. a chatbot that provides users with the ability to find answers on a website by themselves</strong></li>
<li><strong>C. telephone voice menus to reduce the load on human resources</strong></li>
<li>D. a service that creates frequently asked questions (FAQ) documents by crawling public websites</li>
</ul>
<p>B: A bot is an automated software program designed to perform a particular task. Think of it as a robot without a body.</p>
<p>C: Automated customer interaction is essential to a business of any size. In fact, 61% of consumers prefer to communicate via speech, and
most of them prefer self-service. Because customer satisfaction is a priority for all businesses, self-service is a critical facet of any customerfacing communications strategy.</p>
<p>180 For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li>Azure Bot Service and Azure Cognitive Services can be integrated.     <strong>（YES）</strong></li>
<li>Azure Bot Service engages with customers in a conversational manner.   <strong>（YES）</strong></li>
<li>Azure Bot Service can import frequently asked questions (FAQ) to question and answer sets.  <strong>（No）</strong></li>
</ul>
<p>Box 1: Yes -</p>
<p><strong>Azure bot service can be integrated with the powerful AI capabilities with Azure Cognitive Services.</strong></p>
<p>Box 2: Yes -</p>
<p>Azure bot service engages with customers in a conversational manner.</p>
<p>Box 3: No -</p>
<p><strong>The QnA Maker service creates knowledge base, not question and answers sets.</strong></p>
<p>Note: You can use the QnA Maker service and a knowledge base to add question-and-answer support to your bot. When you create your knowledge base, you seed it with questions and answers.</p>
<p>181 For each of the following statements, select Yes if the statement is true. Otherwise, select No</p>
<ul>
<li>A webchat bot can interact with users visiting a website. <strong>(Yes)</strong></li>
<li>Automatically generating captions for pre-recorded videos is an example of conversational AI.  <strong>(No)</strong></li>
<li>A smart device in the home that responds to questions such as "What will the weather like today?" is an example of conversational AI.  <strong>(Yes)</strong></li>
</ul>
<p>181 You have a knowledge base of frequently asked questions (FAQ)</p>
<p>You create a bot that uses the knowledge base to respond to customer requests.</p>
<p>You need to identify what the bot can perform without adding additional skills.</p>
<p>What should you identify?</p>
<ul>
<li>A. Register customer purchases.</li>
<li>B. Register customer complaints.</li>
<li><strong>C. Answer questions from multiple users simultaneously</strong>.</li>
<li>D. Provide customers with return materials authorization (RMA) numbers.</li>
</ul>
<p>182 For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<ul>
<li>A webchat bot can interact with users visiting a website.  <strong>(Y)</strong></li>
<li>Automatically generating captions for pre-recorded videos is an example of conversational AI.  <strong>(N)</strong></li>
<li>A smart device in the home that responds to questions such as "What will the weather like today?" is an example of conversational AI.  <strong>(N)</strong></li>
</ul>
<p>183 For each of the following statements, select Yes if the statement is true. Otherwise, select No.</p>
<p>NOTE: Each correct selection is worth one point.</p>
<ul>
<li>Chatbots can only be built by using custom code.     <strong>(N)</strong></li>
<li>The Azure Bot Service provides services that can be used to host conversational bots.   <strong>(Y)</strong></li>
<li>Bots built by using the Azure Bot Service can communicate with Microsoft Teams users.    <strong>(Y)</strong></li>
</ul>
<p><strong>Box 1: No -</strong></p>
<p>Build conversational experiences with Power Virtual Agents and Azure Bot Service</p>
<p>Azure Bot Service provides an integrated development environment for bot building. Its integration with Power Virtual Agents, a fully hosted low-code platform, enables developers of all technical abilities build conversational AI bots no code needed</p>
<p>Box 2: Yes -</p>
<p>Box 3: Yes - You can configure your bot to communicate with people via Microsoft Teams</p>
<p>184 Select the answer that correctly completes the sentence</p>
<p><img alt="Alt Image Text" src="../../images/ai900_2_67.png" title="Body image" /></p>
<p>Azure's Computer Vision service gives you access to advanced algorithms that process images and return information based on the visual features you're interested in</p>
<ul>
<li>Optical Character Recognition (OCR)</li>
<li>Spatial Analysis</li>
<li>Image Analysis</li>
</ul>
<p>The Image Analysis service extracts many visual features from images, such as objects, faces, adult content, and auto-generated text descriptions. Follow the Image Analysis quickstart to get started</p>
<p>185 You have an Azure Machine Learning pipeline that contains a Split Data module.</p>
<p>The Split Data module outputs to a Train Model module and a Score Model module.</p>
<p>What is the function of the Split Data module?</p>
<ul>
<li>A. scaling numeric variables so that they are within a consistent numeric range</li>
<li><strong>B. creating training and validation datasets</strong></li>
<li>C. diverting records that have missing data</li>
<li>D. selecting columns that must be included in the model</li>
</ul>
<p>186 Which statement is an example of a Microsoft responsible AI principe</p>
<ul>
<li>A. AI systems must use only publicly available data</li>
<li><strong>B. AI systems must be transparent and inclusive</strong></li>
<li>C. AI systems must keep personal details public</li>
<li>D. AI systems must protect the interests of the company</li>
</ul>
<p>187 Match the principles of responsible AI to the appropriate descriptions.</p>
<p>To answer, drag the appropriate principle from the column on the left to its description on the right. Each principle may be used once, more than
once, or not at all. You may need to drag the split bar between panes or scroll to view content</p>
<p>Principles</p>
<ul>
<li>Fairness</li>
<li>Inclusiveness</li>
<li>Privacy and security</li>
<li>
<p>Reliability and safety</p>
</li>
<li>
<p>(<strong>Reliability and safety</strong>) AI systems must consistently operate as intended, even under unexpected conditions.</p>
</li>
<li>(<strong>Privacy and security</strong>) AI systems must protect and secure personal and businesses information.</li>
</ul>
<p>188 During the process of Machine Learning, when should you review evaluation metrics.</p>
<ul>
<li>A. Before you train a model.</li>
<li>B. After you clean the data.</li>
<li>C. Before you choose the type of model.</li>
<li><strong>D. After you test a model on the validation data</strong></li>
</ul>
<p>189 You have a natural language processing (NLP) model that was created by using data obtained without permission</p>
<p>Which Microsoft principle for responsible AI does this breach?</p>
<ul>
<li>A. reliability and safety</li>
<li><strong>B. privacy and security</strong></li>
<li>C. inclusiveness</li>
<li>D. transparency</li>
</ul>
<p><strong>Breach of the Microsoft principle for responsible AI known as Privacy, Security, and Compliance</strong></p>
<p>190 Ensuring an AI system does not provide a prediction when important fields contain unusual or missing values is </p>
<p>___ principle for responsible AI.</p>
<ul>
<li>an inclusiveness</li>
<li>a privacy and security</li>
<li><strong>a reliability and safety</strong></li>
<li>a transparency</li>
</ul>
<p>191 Match the services to the appropriate descriptions.</p>
<p>To answer, drag the appropriate service from the column on the left to its description on the right. Each service may be used once, more than
once, or not at all. You may need to drag the split bar between panes or scroll to view content</p>
<ul>
<li>Azure Storage</li>
<li>Azure Bot Service</li>
<li>Language Service</li>
<li>
<p>Speech</p>
</li>
<li>
<p>(<strong>Language Service</strong>) Enables the use of natural language to query a knowledge base.</p>
</li>
<li>( <strong>Speech</strong>) Enables the real-time transcription of speech-to-text.</li>
</ul>
<blockquote>
<p><strong>QnA Maker (now Language) = creates the Knowledge Base</strong></p>
<p>Bot Service - uses the Knowledge Base than Language created</p>
<p>The question asks "... to query a knowledge base"</p>
</blockquote>
<p>192 Which machine learning technique can be used for <strong>anomaly detection?</strong></p>
<ul>
<li>A. A machine learning technique that classifies objects based on user supplied images.</li>
<li>B. A machine learning technique that understands written and spoken language.</li>
<li>C. A machine learning technique that classifies images based on their contents.</li>
<li><strong>D. A machine learning technique that analyzes data over time and identifies unusual changes.</strong></li>
</ul>
<p>193 You have an AI-based loan approval system.</p>
<p>During testing, you discover that the system has a gender bias.</p>
<p>Which responsible AI principle does this violate?</p>
<ul>
<li>A. accountability</li>
<li>B. reliability and safety</li>
<li>C. transparency</li>
<li><strong>D. fairness</strong></li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2020-9999 Jacob Xi
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>